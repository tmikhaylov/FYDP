{"docstore/metadata": {"2db788cc-fdb2-435a-85c5-d5f9272e1afd": {"doc_hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b"}, "eeff5633-dd9e-495c-b291-6cdd7f688259": {"doc_hash": "fe41fd082ddb0c8649ef0ac48529cd0f13d66ccd875edf74ac3cdb8198ad2d95", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "f39d083a-2e3e-405d-a1d3-de008decf882": {"doc_hash": "e21d6757d677ab1472fadb89d6ecd6a23ab155bc24360b0b5fd1e3ab7c33b779", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "792fb115-c6ad-49a5-a428-37ddcae0eae8": {"doc_hash": "0cc3b3726867f1bcba12a7405123d1e535f84da58c11274f0f261a9d724bd172", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "2146e9e2-2fb1-4f36-93d2-fbd5cef27c91": {"doc_hash": "cec4399c750134a10ac8600e361499ad82e89f95be570a19c95dfca0e93cbd31", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "52596574-043d-42af-9aa6-2ac5aa858a10": {"doc_hash": "2d1bf374a29efe2da46706b47b1ad2716ccfcab8f981eb10ab840223353d8ed6", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "b51cdd8f-39ab-4408-bdde-403d4329d8c2": {"doc_hash": "541b74b36fe89daddf83be68b51c274705e66ad791da5e39f965cfff540f8d21", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "16366616-e73d-4b7d-a05d-2f8eb6481a8e": {"doc_hash": "972b6846f8b5b82dd2704dbd8145704f66cd23cb810acbe7f7b614433ea26e0d", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "6b683f45-68bd-4ddb-8833-0dc97c41251e": {"doc_hash": "f121c97bcacc02b5e750f567283b3a572ffae971f97b544139949a96720bdbc9", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "c41c2d5e-e431-4b0c-8cc4-064a6f9077cb": {"doc_hash": "292d538da1797272d16b1fc6558cab9a527c165a43fda91b5c0955ba91360956", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "d747e369-890d-493a-a830-49d6a831506d": {"doc_hash": "d95cb5ddb8ece29bad62fe6da10302efffba2871704c1332882b6130423f7e88", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "7897a05f-6f87-43bb-bedd-657dbc79d48a": {"doc_hash": "015132d97ad1aaf5e8cef9fb503910701ccc4e20893c4eaa761202562a71a492", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "db1619be-4e37-4efc-8e84-5ef34eb3153f": {"doc_hash": "8e15fc6124e869c0badd24b12a185c557fe6f3514cea410b3ff30615062f33fa", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "bb70fc6b-1993-4076-ad91-bb1427ee9d27": {"doc_hash": "cfb0cdb8e9ecd305128d418f36a50bba2985fa6cc112b18cbf2f969bb341c4ca", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "9cfbb92d-3dd9-48c1-95a1-01a3f333969b": {"doc_hash": "52ce2f4a3960bbf54ff02d3a46f5953f647e745182c11e30571a4581c6b21cf2", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "d8e46bbd-080a-4519-96fd-6d28df1dca74": {"doc_hash": "92d17ad312f3ca6226cd90d81091aa9ad1a66896c2b1ad93fa5c710c7bbf81c6", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "0f2086dc-86f2-46ee-9fc4-3d7ec65e782c": {"doc_hash": "737adcdab8ef5c2081bdc8a1ed4b6714bf43fc9ea9576d62c5e1d56e6457ac76", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "c739dc1b-64af-4475-9379-553f5f429a74": {"doc_hash": "a5dba41abc0e39d8ab3edd3de01d5b0cc2b34be03591f1f5b25fedb6b6039bf0", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "fc4fc73a-f083-4bf3-8cb6-ff3f1606b3f9": {"doc_hash": "cceb87acf41b4eeb23bbac072c60983ce9d244714ad8a082e1e966c499f5fff7", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "3aded430-9d46-4b93-801b-21fcab6a02f1": {"doc_hash": "30cebe2b4be534c688a2e9cd759106b8ebff148fda35bb2903ad621f9831af11", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "fbe9d181-82dc-4f7b-afc0-ab6992f62233": {"doc_hash": "bfec7ade0f60eaa212f8dbdcee7fcd8dbf6ca0ebfc84e951f81abd327f578f83", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "20ad84dd-9d5f-48ba-95ee-b537b6201223": {"doc_hash": "e1da4653ffc230b9902b08acbbabf0c64c57c3e1f42fe3f2d560191de757d727", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "7a3971e3-1676-4996-8aec-f0b2bee55abc": {"doc_hash": "0a9307db46fcbad5ab494b42a35ae1dd0b2559de73ec76268c34eba6e6d38b07", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "004921a2-cad6-416c-9b4d-580d8208d508": {"doc_hash": "a4b3c48c3bf1bb03b895f170d500bf0c7e6ca0ed981cec2630703472887fea65", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "db000a10-c025-473f-bc19-bf9d0fbee47c": {"doc_hash": "1c851bbc35ab642570ff8c33fda40463b8e6b459d8094ddb6beb2f79749543bf", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "3e14b145-f2ed-4771-990d-ed6d8b43463d": {"doc_hash": "7f56a77f0a25896a7895c13b3899eca7bd355200a543fa1f4d8a83bbbacedda3", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "9e2e718d-668d-4466-b854-8ac72f90b1d5": {"doc_hash": "b58a95a4af057c17f8effd4a0330e7b0a3b174629b9860bb4844c064cf15dc9c", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "f460512b-c36c-490d-946f-ff954d410605": {"doc_hash": "2ab250c9c90044f59460119d98667614cbf7af1dc4990c62b655dcb8e2c85772", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "c6948006-a008-4953-be8c-72810d5a10ae": {"doc_hash": "7671f96c9424cbb14873d55f87bd40c9684acfec40755d5eceda7a36f2d38005", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "c837d2ad-7549-438f-b65a-b85d14d5e56b": {"doc_hash": "be1f38b4ba7d10e883e7aecc223a9a59edde0f30ba2a48c5272658dee7d936ad", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "895a9d59-1e28-4753-bc46-84a1be19a090": {"doc_hash": "50c3e97e6d8120c6e0821a4d0db7d111872fe8e1e3f35376ef816cb5b9bc4431", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "7f97de6b-3235-491d-bd7b-91adfde98655": {"doc_hash": "7c3bdb999ab5ff0aba6d71be6aaf6574571f6b459f7e687d9ab1dbadec2ba2e8", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "417a288e-7421-44bf-998b-29e205d8eb4a": {"doc_hash": "05e402de624f38869e68240508ee3bd9785a3f44d06566e3ccd251bf0fe6bd9f", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "f175f641-1143-4c5b-85f2-c922e83c37be": {"doc_hash": "69a8ba821467aced3bd5a88b3b550c157c60feedf0318682fa94599e4d02fdc0", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "b3f636f4-49f2-4783-8aab-d67a8843f0fe": {"doc_hash": "2cb03f98787b23bd4f39d4722e286da0bcc0ced6e128849989c179e40ccb9375", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "ca0bdf4f-0746-4f00-83ab-683f3fdeab7a": {"doc_hash": "3dee601b71db0bc53c492f5b26aa9e1196f90fdfec246c6f09607b21db1c8d9c", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "8e9a0cfa-6cde-4e0d-8e4e-a1bd33ab8660": {"doc_hash": "b78404958c02ffc0d3bf4a36618c87635eae66046670aa68bcaa0ad498a1b682", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "e749f28e-983e-40a3-a8a5-fc8cff84dcb9": {"doc_hash": "b3fa0e265cb868dec30cd2af9ff1386e77325d9af04ab4fbcd491f8f579216ba", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}, "b1f6fac4-e7cb-4d59-b33a-ad7e50e30562": {"doc_hash": "2b62b97cf9f87ddf4ab91daff5a50d3a024f8672b9272b36ba7f00756439fa00", "ref_doc_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd"}}, "docstore/data": {"eeff5633-dd9e-495c-b291-6cdd7f688259": {"__data__": {"id_": "eeff5633-dd9e-495c-b291-6cdd7f688259", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f39d083a-2e3e-405d-a1d3-de008decf882", "node_type": "1", "metadata": {}, "hash": "9933694e8201527a5b6058580ef9010bbfdf406ca8a923cb0beb89f5909337a5", "class_name": "RelatedNodeInfo"}}, "text": "[MISSING_PAGE_EMPTY:1]\r\n\r\n**Examining Committee Membership**\r\n\r\nThe following served on the Examining Committee for this thesis. The decision of the Examining Committee is by majority vote.\r\n\r\n\\begin{tabular}{l l} Supervisor(s): & Mark Crowley \\\\  & Professor, Dept. of Electrical and Computer Engineering, \\\\  & University of Waterloo \\\\ Reader: & Zhou Wang \\\\  & Professor, Dept. of Electrical and Computer Engineering, \\\\  & University of Waterloo \\\\ Reader: & Kate Larson \\\\  & Professor, Dept. of Computer Science, University of Waterloo \\\\ \\end{tabular}\r\n\r\n**Author's Declaration**\r\n\r\nI hereby declare that I am the sole author of this thesis. This is a true copy of the thesis, including any required final revisions, as accepted by my examiners.\r\n\r\nI understand that my thesis may be made electronically available to the public.\r\n\r\n###### Abstract\r\n\r\nWildfires have become a pressing issue globally, with their increasing frequency and intensity causing significant environmental, economic, and human impacts. Traditional wildfire prediction methods, while useful, often fall short in time complexity or simulation on heterogeneous landscapes. This thesis explores the application of deep learning models, especially convolutional networks, to improve the accuracy and reliability of wildfire spread predictions. By leveraging advanced machine learning techniques, this research aims to enhance the current prediction capabilities and provide better tools for Canadian wildfire management and mitigation.\r\n\r\nUtilizing a comprehensive dataset from various sources, this thesis integrates multiple features such as weather data, vegetation types, and topographical information. The research introduces a novel module for fusing multi-modal data, which enhances the performance of U-shape deep learning models like U-Net. Additionally, an innovative U-shape network structure with atrous convolution and new attention implementation was developed to further improve prediction accuracy. The thesis also proposes an enhancement method that amplifies grouped error pixels for element-wise error computation for model training. The novel data fusion module proposed in this thesis has been proven to improve the baseline model on the F1 score, while the new model I suggest outperformed the baseline model and its two variants on the same metric. In the final part of the thesis I proposed various additional enhancement methods to improve performance further, it has shown its statistical significance under certain conditions when applied to BCELoss.\r\n\r\nBy enhancing the predictive capabilities of wildfire spread models, this thesis offers valuable insights for emergency responders and policymakers, aiding in better resource allocation and risk mitigation strategies. The deep learning methodologies developed in this study are versatile and have potential applications in other fields requiring spatial data predictions, such as intelligent healthcare, flood forecasting, and disease spread modelling.\r\n\r\n**Acknowledgements**\r\n\r\nI would like to thank my family for their support and encouragement throughout my master's studies. Their belief in me has been invaluable.\r\n\r\nI am also grateful to my supervisor, Mark Crowley, for his guidance and assistance. His expertise has been essential in the development of this thesis.\r\n\r\nAdditionally, I appreciate the help from researchers outside the university who assisted with data collection and provided background training. Their contributions have been greatly appreciated.\r\n\r\n## Table of Contents\r\n\r\n### Examining Committee\r\n\r\n**Author's Declaration**\r\n\r\n**Abstract**\r\n\r\n**Acknowledgements**\r\n\r\n**List of Figures**\r\n\r\n**List of Tables**\r\n\r\n## 1 Introduction\r\n\r\n### 1.1 Thesis Tasks\r\n\r\n### 1.2 Research Frame Design\r\n\r\n**Background Knowledge**\r\n\r\n**2.1 Wildfire Background Information**\r\n\r\n**2.1.1 Fuel Type in FBP System**\r\n\r\n**2.1.2 Fire Weather Index System**\r\n\r\n**2.2 Machine Learning Background Information**\r\n\r\n**2.2.1 Machine Learning and Deep Learning**\r\n\r\n**2.2.2 Convolutions and Convolution Neural Networks**\r\n\r\n#### 2.2.3 Attention Mechanisms\r\n\r\n* 2.2.4 U-Net, U-Net++++, Swin-UNet\r\n\t* 2.3 Significance Testing\r\n\t\t* 2.3.1 Significance Testing and the P-Value\r\n\t\t* 2.3.2 Paired Samples T-Test\r\n* 3 Literature Review for Wildfire Prediction Tools\r\n\t* 3.1 Traditional Tools\r\n\t\t* 3.1.1 Rothermel Fire Spread Equations\r\n\t\t* 3.1.2 Fire Behavior Prediction (FBP) System\r\n\t\t* 3.1.3 FARSITE\r\n\t\t* 3.1.4 Prometheus, Burn-P3 and Burn-P3+\r\n\t* 3.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4500, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f39d083a-2e3e-405d-a1d3-de008decf882": {"__data__": {"id_": "f39d083a-2e3e-405d-a1d3-de008decf882", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eeff5633-dd9e-495c-b291-6cdd7f688259", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "fe41fd082ddb0c8649ef0ac48529cd0f13d66ccd875edf74ac3cdb8198ad2d95", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "792fb115-c6ad-49a5-a428-37ddcae0eae8", "node_type": "1", "metadata": {}, "hash": "656a13dd2e12bf08bbeb4c51637785f6a4b1cb00d17077260f3180f55936f8f3", "class_name": "RelatedNodeInfo"}}, "text": "2.1 Machine Learning and Deep Learning**\r\n\r\n**2.2.2 Convolutions and Convolution Neural Networks**\r\n\r\n#### 2.2.3 Attention Mechanisms\r\n\r\n* 2.2.4 U-Net, U-Net++++, Swin-UNet\r\n\t* 2.3 Significance Testing\r\n\t\t* 2.3.1 Significance Testing and the P-Value\r\n\t\t* 2.3.2 Paired Samples T-Test\r\n* 3 Literature Review for Wildfire Prediction Tools\r\n\t* 3.1 Traditional Tools\r\n\t\t* 3.1.1 Rothermel Fire Spread Equations\r\n\t\t* 3.1.2 Fire Behavior Prediction (FBP) System\r\n\t\t* 3.1.3 FARSITE\r\n\t\t* 3.1.4 Prometheus, Burn-P3 and Burn-P3+\r\n\t* 3.2 Machine Learning Literature Review\r\n\t\t* 3.2.1 Machine Learning in Fire Spread Predictions\r\n\t\t* 3.2.2 Machine Learning in Fire Occurrence Predictions\r\n\t\t* 3.2.3 A Review of Machine Learning Applications in Wildfire Science and Management\r\n* 4 Data Acquisition and Processing\r\n\t* 4.1 National Wildfire Dataset\r\n\t* 4.2 Burned Area and Hotspot\r\n\t\t* 4.2.1 Sight Window, Mask and Resample\r\n\t\t* 4.2.2 Estimated Burning Areas\r\n\t\t* 4.2.3 Cumulative Burning Areas\r\n\t* 4.3 Fuel\r\n\t* 4.4 Elevation\r\n\t* 4.5 Fire Weather Index\r\n\t* 4.6 Tebular(1D) Features\r\n\t\t* 4.6.1 Agency\r\n\t\t* 4.6.2 Temporal Feature\r\n\t\t* 4.6.3 Fire Cause\r\n* 5 Fusion of Heterogeneous Features\r\n\t* 5.1 Block Structure\r\n\t* 5.2 Performance\r\n\t\t* 5.2.1 Ablation study on 1D features\r\n\t\t* 5.2.2 Controlled Experiment with MLP\r\n\t\t* 5.2.3 Experimental Result Analysis\r\n* 6 Burned Area Prediction\r\n\t* 6.1 Experiment Design\r\n\t\t* 6.1.1 Hyperparameters\r\n\t\t* 6.1.2 Loss\r\n\t\t* 6.1.3 Optimizers\r\n\t\t* 6.1.4 Evaluation Metrics\r\n\t\t* 6.1.5 Additional Settings\r\n\t* 6.2 Past Work Reproduction\r\n\t\t* 6.2.1 ANN\r\n\t\t* 6.2.2 DCIGN\r\n\t\t* 6.2.3 FireCast\r\n\t\t* 6.2.4 Experimental Result and Analysis\r\n\t* 6.3 Comparing Convolutional U-Shape Networks and Attention-Based U-Shape Networks\r\n\t\t* 6.3.1 U-Net\r\n\t\t* 6.3.2 Extensions\r\n\t\t* 6.3.3 Experimental Result\r\n* 7 AA-Unet, a New Multi-scale, Convolutional Attention Based Architecture\r\n\t* 7.1 AA-Unet\r\n\t* 7.2 Atrous Spatial Pyramid Convolution (ASPC)\r\n\t* 7.3 Windowed Convolutional Attention (WCA)\r\n\t* 7.4 Multi-Head WCA\r\n\t* 7.5 Experimental Result\r\n\t* 7.6 Ablation Study\r\n* 8 Spread Error Attenuation Field (SEAF)\r\n\t* 8.1 Introduction\r\n\t* 8.2 Core Idea\r\n\t\t* 8.2.1 SEAF Kernel\r\n\t\t* 8.2.2 Layer Definition\r\n\t\t* 8.2.3 Weight Calculation of Pixels\r\n\t\t* 8.2.4 OR Operation After Spread Using Error Mask (optional)\r\n\t\t* 8.2.5 Additional Scaling Factor (optional)\r\n\t\t* 8.2.6 IoU Scaling Factor (optional)\r\n\t\t* 8.2.7 Experimental Result\r\n* 9 Conclusions and Future Works\r\n\t* 9.1 Conclusions\r\n\t* 9.2 Future Works\r\n\t\t* 9.2.1 Dataset Making\r\n\t\t* 9.", "mimetype": "text/plain", "start_char_idx": 3977, "end_char_idx": 6508, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "792fb115-c6ad-49a5-a428-37ddcae0eae8": {"__data__": {"id_": "792fb115-c6ad-49a5-a428-37ddcae0eae8", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f39d083a-2e3e-405d-a1d3-de008decf882", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "e21d6757d677ab1472fadb89d6ecd6a23ab155bc24360b0b5fd1e3ab7c33b779", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2146e9e2-2fb1-4f36-93d2-fbd5cef27c91", "node_type": "1", "metadata": {}, "hash": "de12fe54dc9c16f6aec1ee964d0841534554e40ffd34ff87869531e91a0644ab", "class_name": "RelatedNodeInfo"}}, "text": "5 Experimental Result\r\n\t* 7.6 Ablation Study\r\n* 8 Spread Error Attenuation Field (SEAF)\r\n\t* 8.1 Introduction\r\n\t* 8.2 Core Idea\r\n\t\t* 8.2.1 SEAF Kernel\r\n\t\t* 8.2.2 Layer Definition\r\n\t\t* 8.2.3 Weight Calculation of Pixels\r\n\t\t* 8.2.4 OR Operation After Spread Using Error Mask (optional)\r\n\t\t* 8.2.5 Additional Scaling Factor (optional)\r\n\t\t* 8.2.6 IoU Scaling Factor (optional)\r\n\t\t* 8.2.7 Experimental Result\r\n* 9 Conclusions and Future Works\r\n\t* 9.1 Conclusions\r\n\t* 9.2 Future Works\r\n\t\t* 9.2.1 Dataset Making\r\n\t\t* 9.2.2 Data Augmentation\r\n\t\t* 9.2.3 Multi-Class Prediction\r\n\t\t* 9.2.4 Comparison to traditional models\r\n\r\nList of Figures\r\n* 1.1 The Frame of Prediction Model\r\n* 1.2 An example of ground truth(L) and prediction output(R)\r\n* 2.1 CFFDRS [27]\r\n* 2.2 FWI System [28]\r\n* 2.3 2D Convolution Demonstration (kernel=3 stride=1)\r\n* 2.4 Atrous Convolution Demonstration on kernel size = 3\r\n* 2.5 Scaled Dot-product Attention [36]\r\n* 2.6 Multi-head Attention [36]\r\n* 2.7 Original U-Net [31]\r\n* 4.1 Canadian provincial and territorial boundaries\r\n* 4.2 KDE of burned areas from 1994 to 2021 with 95 percent mark\r\n* 4.3 KDE of 95 percent burned areas from 1994 to 2021\r\n* 4.4 The Bounding Box and affine transformation Matrix\r\n* 4.5 Estimated Burning Areas\r\n* 4.6 Cumulative Burned Areas\r\n* 4.7 Elevation from Multiple Tiles\r\n* 5.1 Hybrid Bottleneck Block in U-shape encoder-decoder\r\n* 5.2 Hybrid Bottleneck Block\r\n* 5.3 Controlled Experiment on Resnet 18* [61] U-Net+HBN Structure\r\n* [62] 5-fold loss curve of U-Net\r\n* [63] Feature aggregation on \\(X_{de}^{2}\\) in U-Net 3+\r\n* [64] Swin Transformer Block [7]\r\n* [65] 5-fold loss curve of U-Net 3p(L) and Swin-Unet(R)\r\n* [66] AA-Unet+HBN Structure\r\n* [67] 7.2 Atrous Spatial Pyramid Convolution (ASPC)\r\n* [68] 7.3 Windowed Convolutional Attention (WCA)\r\n* [69] 7.4 Data Flow in WCA\r\n* [70] 7.5 Data Flow in Multi-head WCA\r\n* [71] A SEAF Example with grouped error\r\n* [72] 8.2 A SEAF Example without grouped error\r\n* [73] 8.3 SEAF Kernel\r\n* [74] Grid A(Left) & Grid B(Right)\r\n* [75] An example of prediction: Ground Truth(L), AA-Unet trained on BCELoss(C) and trained on SEAF-BCELoss(R)List of Tables\r\n\t* 1.1 Fire Sample Metadata\r\n\t* 4.1 Burned Areas in Hectares (Canada, 1994-2021)\r\n\t* 4.2 List of Abbreviations\r\n\t* 4.3 Fire Event Counts Per Province, Territory and National Park Canada (1994-2021)\r\n\t* 4.4 Hotspot Yearly Counts (1994-2021)\r\n\t* 4.5 Canadian Forest FBP Fuel Types\r\n\t* 4.6 Fire Cause Values and Descriptions\r\n\t* 5.1 Performance Metrics of the Ablation Study\r\n\t* 5.2 T-test on U-Net+HBN and U-Net\r\n\t* 5.3 Perfomance Metrices of the Controlled Experiment\r\n\t* 6.1 ANN\r\n\t* 6.2 DCGN\r\n\t* 6.3 FireCast\r\n\t* 6.", "mimetype": "text/plain", "start_char_idx": 5997, "end_char_idx": 8657, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2146e9e2-2fb1-4f36-93d2-fbd5cef27c91": {"__data__": {"id_": "2146e9e2-2fb1-4f36-93d2-fbd5cef27c91", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "792fb115-c6ad-49a5-a428-37ddcae0eae8", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "0cc3b3726867f1bcba12a7405123d1e535f84da58c11274f0f261a9d724bd172", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "52596574-043d-42af-9aa6-2ac5aa858a10", "node_type": "1", "metadata": {}, "hash": "3a5f90a88f948def7ac6762439973e338952627f68831e48d2e5880ccd4ec20e", "class_name": "RelatedNodeInfo"}}, "text": "1 Fire Sample Metadata\r\n\t* 4.1 Burned Areas in Hectares (Canada, 1994-2021)\r\n\t* 4.2 List of Abbreviations\r\n\t* 4.3 Fire Event Counts Per Province, Territory and National Park Canada (1994-2021)\r\n\t* 4.4 Hotspot Yearly Counts (1994-2021)\r\n\t* 4.5 Canadian Forest FBP Fuel Types\r\n\t* 4.6 Fire Cause Values and Descriptions\r\n\t* 5.1 Performance Metrics of the Ablation Study\r\n\t* 5.2 T-test on U-Net+HBN and U-Net\r\n\t* 5.3 Perfomance Metrices of the Controlled Experiment\r\n\t* 6.1 ANN\r\n\t* 6.2 DCGN\r\n\t* 6.3 FireCast\r\n\t* 6.4 Performance Metrics for Reproduced Models\r\n\t* 6.5 Performance Metrics of U-Net/U-Net 3P/Swin-Unet with HBN\r\n\t* 6.6 T-test on U-Net 3p and Swin-Unet (with/without HBN)\r\n\t* 7.1 Performance Metrics of AA-Unet, U-Net, U-net 3+ and Swin-Unet\r\n\t* 7.2 T-test on AA-Unet/U-Net with HBN\r\nPerformance Metrics of the Ablation Study on AA-Unet\r\n* 8.1 Performance Metrics of BCELoss/SEAF-BCELoss on AA-Unet+HBN\r\n* 8.2 T-test on AA-Unet using SEAF-BCELoss/BCELoss with HBN\r\n\r\n## Chapter 1 Introduction\r\n\r\nThe wildland fires (wildfires in short) in Canada are becoming an increasingly severe issue. In recent years, they have become more frequent and intense, affecting vast areas and resulting in great financial loss to the country. As a result of climate change, the weather has become hotter and drier, worsening the situation by increasing the possibility of ignition and spread, resulting in higher costs for fire management and recovery. With certain conditions, burning pollution such as ozone or carbon monoxide [6] could spread for very long distances and leave a long-term threat to human health. These trends emphasize the importance of fire behaviour prediction. Due to the complexity and randomness of fire hazard factors such as weather, human activity and fuel type, this prediction task is challenging.\r\n\r\nTraditional wildfire prediction methods mainly rely on the statistics from historical data and expert judgment. However, the dynamic nature and complexity of wildfires in recent years, especially with large and multi-dimensional datasets obtained from satellites and other sources, may require more adaptive and sophisticated methods. Additionally, traditional methods could have less tolerance for error, distortion and disappearance in datasets.\r\n\r\nMachine learning techniques, particularly deep learning, have shown their great performance in many fields. By transforming the wildfire behaviour prediction task into specific classification or regression tasks, deep learning models, introduce the great potential of dealing with several features, identifying complex relationships and adaptive learning. Some recent research has suggested the potential of deep learning technologies to outperform traditional methods in some wildfire prediction tasks. For example, Ghali and Akhloufi [15] provided a comprehensive review of deep learning solutions on severalwildland fire-related tasks including prediction, reflecting the capabilities for deep learning models learning complex wildfire behaviour.\r\n\r\nThis thesis focuses on exploring national-level wildfire spread prediction tasks using deep learning models. The research aims to improve the comprehensive performance of wildfire spread predictions and contribute to saving wildfire control and reaction costs such as resource allocation, damage prevention or minimization, rescue and evacuation. The research converted full procedures from data collection to model training and analysis. In data preparation, several sets of data with different attributes were gathered and merged by using different processing methods to ensure good alignment. Then a new module for fusing features with different dimensions was introduced, which provides an efficient way to feed data to U-shape deep learning models. After that, I proposed a novel structure based on U-Net which has the potential to not only help wildfire prediction but also spatial prediction/classification/segmentation tasks in other fields. Finally, an enhancement method for the 2D criterion function relying on element-wise error was proposed.\r\n\r\n### 1.1 Thesis Tasks\r\n\r\nThe research aims to provide deep learning solutions with better performance than existing tools on the wildfire next-day (step-wise) burned area prediction task.", "mimetype": "text/plain", "start_char_idx": 8147, "end_char_idx": 12415, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "52596574-043d-42af-9aa6-2ac5aa858a10": {"__data__": {"id_": "52596574-043d-42af-9aa6-2ac5aa858a10", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2146e9e2-2fb1-4f36-93d2-fbd5cef27c91", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "cec4399c750134a10ac8600e361499ad82e89f95be570a19c95dfca0e93cbd31", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b51cdd8f-39ab-4408-bdde-403d4329d8c2", "node_type": "1", "metadata": {}, "hash": "d0c957c473cbd4d3c84be3d048a7c6d33963e3c8a2f1c90a425d7c09777b8262", "class_name": "RelatedNodeInfo"}}, "text": "The research converted full procedures from data collection to model training and analysis. In data preparation, several sets of data with different attributes were gathered and merged by using different processing methods to ensure good alignment. Then a new module for fusing features with different dimensions was introduced, which provides an efficient way to feed data to U-shape deep learning models. After that, I proposed a novel structure based on U-Net which has the potential to not only help wildfire prediction but also spatial prediction/classification/segmentation tasks in other fields. Finally, an enhancement method for the 2D criterion function relying on element-wise error was proposed.\r\n\r\n### 1.1 Thesis Tasks\r\n\r\nThe research aims to provide deep learning solutions with better performance than existing tools on the wildfire next-day (step-wise) burned area prediction task. In this thesis, the task is identified as binary classification on the 2D grid from two consecutive days of data. The model takes several features from one day and then predicts the combination of the burning area and the burned area of the next day.\r\n\r\nThe wildfire input features in this thesis contain both spatial(2D) and tabular(1D) features which are not compatible with most of the deep learning models that were designed to take single-modal input. The first task is about the efficient solution of data fusion in the prediction task. The performance of the solution could be valued by comparison to a simple implementation of a fusion module using Muli-Layer Perceptron (MLP).\r\n\r\nConsidering the situation that deep learning techniques have not been commonly adopted in this field, the second goal is to choose a modern model that performed well in a similar task and test its behaviour on the wildfire prediction task. The U-Net [32] structure has shown its high efficiency in medical imaging segmentation and the design has influenced the progress in multiple research fields. Because of the similarities between medical imaging segmentation and fire spread shape segmentation, U-Net was chosen to be the baseline model. Based on the idea of a baseline model, I investigate the possibility of better performance on variants of the U-Net structure. UNet 3+ increases the number of connectionsamong layers and Swin-Unet replaces the convolution module with a windowed attention module.\r\n\r\nThe last task is bringing better prediction performance which is the main value of this research. Inspired by the ideas of the above models, a new U-shape network containing two key modules was proposed. This network was tested against the three existing models to prove its strength. Besides the prediction model, I have also explored the possibility of enhancing grouped error during loss calculation. A method was recommended which can amplify localized error pixels during element-wise error calculation. It was tested on the loss function adopted in this thesis.\r\n\r\n### 1.2 Research Frame Design\r\n\r\nThe prediction model takes two inputs and generates one output. One input contains five spatial features including ideal geographical shape, weather, vegetation and historical shape of fire. Another input contains three supplementary tabular features regarding metadata such as the region or the reason for fire occurrence. The model is expected to predict the shape of the next-day burned area as a spatial map (grid map).\r\n\r\nFigure 1.1: The Frame of Prediction Model\r\n\r\nFigure 1.2 shows an illustration of the content of output from prediction models. The input sample comes from a day of a wildfire that happened in Alberta in 2010. A brief metadata is provided through table 1.1.\r\n\r\nThe figure shows the ground truth shape of the next-day burned area on the left and the prediction for it on the right. The ground truth is historical data from the dataset and the prediction is from the prediction mode. This thesis has covered several deep learning models but they have the same output configurations. The red and yellow in prediction output stand for false negative(burned pixels not reported by model) and false positive(reported pixels which did not burn). These two kinds of false predictions were not acquired and classified from the model's output. They were computed through extra scripts for visual analysis.", "mimetype": "text/plain", "start_char_idx": 11518, "end_char_idx": 15839, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b51cdd8f-39ab-4408-bdde-403d4329d8c2": {"__data__": {"id_": "b51cdd8f-39ab-4408-bdde-403d4329d8c2", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "52596574-043d-42af-9aa6-2ac5aa858a10", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "2d1bf374a29efe2da46706b47b1ad2716ccfcab8f981eb10ab840223353d8ed6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "16366616-e73d-4b7d-a05d-2f8eb6481a8e", "node_type": "1", "metadata": {}, "hash": "324b55205d152b14df16fcbf9fc6d61f4e7729b94ecd6d5a69522e1202af1b3f", "class_name": "RelatedNodeInfo"}}, "text": "Figure 1.1: The Frame of Prediction Model\r\n\r\nFigure 1.2 shows an illustration of the content of output from prediction models. The input sample comes from a day of a wildfire that happened in Alberta in 2010. A brief metadata is provided through table 1.1.\r\n\r\nThe figure shows the ground truth shape of the next-day burned area on the left and the prediction for it on the right. The ground truth is historical data from the dataset and the prediction is from the prediction mode. This thesis has covered several deep learning models but they have the same output configurations. The red and yellow in prediction output stand for false negative(burned pixels not reported by model) and false positive(reported pixels which did not burn). These two kinds of false predictions were not acquired and classified from the model's output. They were computed through extra scripts for visual analysis.\r\n\r\n\\begin{table}\r\n\\begin{tabular}{c c c c c c c c c} \\hline \\hline NFIREID & YEAR & AGENCY & FIRECAUS & Total Burned Are (Hectares) & Burning Days & Estimated Start Date & Estimated End Date & Geometry Shape \\\\ \\hline\r\n205 & 2010 & AB & Lightning & 26961.4665 & 78 & 6/15/2010 & 9/1/2010 & multi-polygon \\\\ \\hline \\hline \\end{tabular}\r\n\\end{table}\r\nTable 1.1: Fire Sample Metadata\r\n\r\nFigure 1.2: An example of ground truth(L) and prediction output(R)\r\n\r\n## Chapter 2 Background Knowledge\r\n\r\nThis chapter aims to provide background knowledge related to the studies of this thesis. By explaining relevant topics, it is expected to help the readers understand the contents of the following chapters regarding my work.\r\n\r\n### 2.1 Wildfire Background Information\r\n\r\nWildland fires, which are also known as wildfires or forest fires, are uncontrolled fires occurring in areas covered by various vegetation. Much area in Canada is covered with forests and plant life, making these regions highly susceptible to wildfires. The unpredictable nature of the causes of wildfires makes it challenging to predict the precise occurrence of these fires. Reliable predictions of wildfire growth are crucial as they could lead to an efficient allocation of resources during firefighting efforts.\r\n\r\nThe intensity and spread of fires are influenced by three primary factors, known as the \"fire behaviour triangle\": Fuel, Weather, and Topography. Canada has employed a Canadian Forest Fire Danger Rating System (CFFDRS) [27] as the national fire risk system, which includes two critical tools for predicting and managing wildfires: the Fire Behavior Prediction (FBP) Fuel System and the Fire Weather Index (FWI).\r\n\r\n#### Fuel Type in FBP System\r\n\r\nThe Fire Behavior Prediction (FBP) Fuel System is one of the key components of the CFFDRS. It offers detailed predictions of wildfire behaviour based on specific fuel types and conditions. The FBP system categorizes fuels into various types based on their physical characteristics. Each class is unique regarding forest floors and organic layers, fuels at the surface and ladder, also the stand structure and composition.\r\n\r\n#### Fire Weather Index System\r\n\r\nThe Fire Weather Index (FWI) [28] is another core component of the CFFDRS. It assesses the risk and potential behaviour of wildfires based on daily weather observations. The FWI system integrates several sub-indices to provide a comprehensive assessment of fire danger. FWI is the final output in the system and is a numerical wildfire threat indicator, used as a general index of fire danger throughout the forested areas of Canada.\r\n\r\nFigure 2.1: CFFDRS [27]\r\n\r\n### 2.2 Machine Learning Background Information\r\n\r\n#### Machine Learning and Deep Learning\r\n\r\nMachine Learning is a subset of the Artificial Intelligence (AI) field of study that enables computers to learn the pattern of data and perform tasks such as classification, prediction, decision-making and much more. Deep learning is a subset of machine learning that mainly focuses on neural networks. Deep learning has shown its great capabilities for many tasks and its greater potential to outperform traditional tools in some fields.\r\n\r\n#### Convolutions and Convolution Neural Networks\r\n\r\n##### Convolutions and CNN\r\n\r\nThe traditional convolution is a mathematical operation that takes two functions and produces a third function.", "mimetype": "text/plain", "start_char_idx": 14945, "end_char_idx": 19221, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "16366616-e73d-4b7d-a05d-2f8eb6481a8e": {"__data__": {"id_": "16366616-e73d-4b7d-a05d-2f8eb6481a8e", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b51cdd8f-39ab-4408-bdde-403d4329d8c2", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "541b74b36fe89daddf83be68b51c274705e66ad791da5e39f965cfff540f8d21", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6b683f45-68bd-4ddb-8833-0dc97c41251e", "node_type": "1", "metadata": {}, "hash": "a4b76c02c6732ebefcc5c706b91f1b2b0fcd09f3dd53306cc10ff8724709b01e", "class_name": "RelatedNodeInfo"}}, "text": "The FWI system integrates several sub-indices to provide a comprehensive assessment of fire danger. FWI is the final output in the system and is a numerical wildfire threat indicator, used as a general index of fire danger throughout the forested areas of Canada.\r\n\r\nFigure 2.1: CFFDRS [27]\r\n\r\n### 2.2 Machine Learning Background Information\r\n\r\n#### Machine Learning and Deep Learning\r\n\r\nMachine Learning is a subset of the Artificial Intelligence (AI) field of study that enables computers to learn the pattern of data and perform tasks such as classification, prediction, decision-making and much more. Deep learning is a subset of machine learning that mainly focuses on neural networks. Deep learning has shown its great capabilities for many tasks and its greater potential to outperform traditional tools in some fields.\r\n\r\n#### Convolutions and Convolution Neural Networks\r\n\r\n##### Convolutions and CNN\r\n\r\nThe traditional convolution is a mathematical operation that takes two functions and produces a third function. The convolution of two continuous functions \\(f(t)\\) and \\(g(t)\\) is defined as:\r\n\r\n\\[(f*g)(t)=\\int_{-\\infty}^{\\infty}f(\\tau)g(t-\\tau)\\,d\\tau \\tag{2.1}\\]\r\n\r\nFigure 2.2: FWI System [28]\r\n\r\n[MISSING_PAGE_EMPTY:21]\r\n\r\nConvolutional Neural Networks (CNNs) are a class of deep learning models specifically designed to process and analyze visual data. They utilize convolutional layers to learn spatial hierarchies of features from input images. By applying various filters across the input, CNNs can detect patterns such as edges, textures, and more complex structures at different layers. These learned features are crucial for tasks like image classification, object detection, and segmentation, making CNNs highly effective in computer vision applications.\r\n\r\n##### Deconvolution and Transposed Convolution\r\n\r\nDeconvolution is the reverse process of convolution and it requires the arguments in convolutional kernels. Transposed Convolution is a computing process that follows the procedure of deconvolution but uses independent kernels. In this thesis paper, both terms \"deconvolution\" and \"transposed convolution\" refer to the definition of transposed convolution.\r\n\r\nFigure 2.3: 2D Convolution Demonstration (kernel=3 stride=1)\r\n\r\nAtrous convolution (dilated convolution) is a convolution method that increases the field of view of the model without greatly increasing the computational cost. The atrous kernel is sparse to cover a large scale of data without losing details. A common implementation of atrous convolution is Atrous Spatial Pyramid Pooling (ASPP) proposed with the model Deeplabv3 [9]. ASPP applies multiple atrous convolution layers in parallel, which enables sampling at different scales and the capability of capturing better long-distance information.\r\n\r\n#### Attention Mechanisms\r\n\r\nAttention mechanisms are an advanced component of deep learning models that allows models to focus on specific parts of data by observing relationships among components of the data. This is particularly useful in many tasks where the important information is not uniformly distributed across all the data. Attention mechanisms enable models to dynamically weigh the importance of different parts of the input data. This is achieved by calculating attention scores that reflect how strongly each part of the data should influence the output.\r\n\r\n##### Self-Attention and Cross Attention\r\n\r\nSelf-attention is a mechanism by which a model weighs the elements in the output from the last layer by their relevance to each other. For example, in a natural language processing\r\n\r\nFigure 2.4: Atrous Convolution Demonstration on kernel size = 3\r\n\r\ntask, the model analyses each word token and calculates the relevance to the other word tokens.\r\n\r\nCross-attention is similar to self-attention but the relevance score is not necessarily computed from only the output of the last layer in the model but also from other layers. The Transformer model uses self-attention in the encoder and decoder part and uses cross-attention in its decoder part.\r\n\r\n##### Scaled Dot-product Attention\r\n\r\nScaled dot-product attention is an implementation of the attention mechanism in the Transformer model [36]. The input of the module goes through three different transformation matrices and becomes three tensors Query, Key and Value (\\(Q\\), \\(K\\), \\(V\\)). The \\(Q\\) and \\(K\\) can be regarded as the representation of the \"question\" side and \"answer\" side and thus the dot matrix production gives a relation score (compatibility in the author's word) between the two.", "mimetype": "text/plain", "start_char_idx": 18197, "end_char_idx": 22768, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6b683f45-68bd-4ddb-8833-0dc97c41251e": {"__data__": {"id_": "6b683f45-68bd-4ddb-8833-0dc97c41251e", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "16366616-e73d-4b7d-a05d-2f8eb6481a8e", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "972b6846f8b5b82dd2704dbd8145704f66cd23cb810acbe7f7b614433ea26e0d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c41c2d5e-e431-4b0c-8cc4-064a6f9077cb", "node_type": "1", "metadata": {}, "hash": "e9a6f9aa21f4d09beda4cb2b24bafb27554ef6a1cf66413e7c8ae364bdb2a81f", "class_name": "RelatedNodeInfo"}}, "text": "Cross-attention is similar to self-attention but the relevance score is not necessarily computed from only the output of the last layer in the model but also from other layers. The Transformer model uses self-attention in the encoder and decoder part and uses cross-attention in its decoder part.\r\n\r\n##### Scaled Dot-product Attention\r\n\r\nScaled dot-product attention is an implementation of the attention mechanism in the Transformer model [36]. The input of the module goes through three different transformation matrices and becomes three tensors Query, Key and Value (\\(Q\\), \\(K\\), \\(V\\)). The \\(Q\\) and \\(K\\) can be regarded as the representation of the \"question\" side and \"answer\" side and thus the dot matrix production gives a relation score (compatibility in the author's word) between the two.\r\n\r\n\\[\\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^{T}}{\\sqrt{d_{k}}}\\right)V \\tag{2.3}\\]\r\n\r\nThe scaled dot-product attention mechanism calculates attention scores by taking the dot product of the Q and K matrices, dividing by the square root of the dimension of the Key vectors (\\(d_{k}\\)) to mitigate the effect of large dot product values, and applying a\r\n\r\nFigure 2.5: Scaled Dot-product Attention [36]\r\n\r\nsoftmax function to obtain the attention weights. These weights are then used to compute a weighted sum of the V matrix, producing the final output.\r\n\r\nThe scaling using the factor \\(d_{k}\\) is to reduce the vanishing gradient problem for terms with high compatibility in dot products with large attribute dimensions. The reason for the problem is many terms are multiplied during the matrix product, resulting in the summation of them approaching the hard limit of the activation functions.\r\n\r\n##### Multi-head Attention\r\n\r\nThe Multi-head attention mechanism projects the input to several different small attribute spaces (similar to channels in CNN) called heads instead of one big attribute space [36]. The size of the attribute space in each head \\(d_{k}\\), \\(d_{v}\\) is computed by dividing the original model's attribute space by head numbers. The computation cost of multi-head attention is similar to single-head attention with full dimensionality but adding diverse projections.\r\n\r\nFigure 2.6: Multi-head Attention [36]\r\n\r\nU-Net is a specific type of Convolutional Neural Network structure that was initially developed for biomedical image segmentation tasks [31]. The network consists of a downsampling path (encoder) and an upsampling path (decoder) with connections between the encoding block and decoding block on the same level.\r\n\r\nU-Net++ (U-Net 3+/U-Net 3p) is a U-Net-based architecture based on another variant of U-Net called U-Net++ [19]. U-Net 3+ increases the number of connections to each block, with attention to improving the ability to capture complex patterns across different layers in the model.\r\n\r\nSwin-UNet is a variant that integrates features of the Swin Transformer into the U-Net architecture [7]. The Swin Transformer is a Transformer architecture that is designed to solve some problems that the Vision Transformer might encounter, for example, the presence of large variations in visual entities, or the difference in resolution between text token and image pixels. The Swin Transformer's core idea is performing self-attention within different patch sizes along the depth and adopting sliding windows to solve the lack of connection among patches. Swin-UNet inherits those features and puts them into the U-Net architecture.\r\n\r\nFigure 2.7: Original U-Net [31]\r\n\r\n### 2.3 Significance Testing\r\n\r\nThe T-test is a statistical hypothesis test used to determine if there is a significant difference between the means of two groups. It is widely used in various fields, including biomedical research, social sciences, and machine learning, to compare the performance of different models or treatments. The T-test can be classified into several types, but the most commonly used ones are the Independent Samples T-test, Paired Samples T-test, and One-Sample T-test. This section will focus on the Paired Samples T-test, which is particularly relevant when comparing the performance of two models on the same dataset.\r\n\r\n#### Significance Testing and the P-Value\r\n\r\nSignificance testing is a statistical technique used to determine whether the observed effect in data is genuine or if it could have occurred by chance. A key concept in significance testing is the p-value.", "mimetype": "text/plain", "start_char_idx": 21965, "end_char_idx": 26389, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c41c2d5e-e431-4b0c-8cc4-064a6f9077cb": {"__data__": {"id_": "c41c2d5e-e431-4b0c-8cc4-064a6f9077cb", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6b683f45-68bd-4ddb-8833-0dc97c41251e", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "f121c97bcacc02b5e750f567283b3a572ffae971f97b544139949a96720bdbc9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d747e369-890d-493a-a830-49d6a831506d", "node_type": "1", "metadata": {}, "hash": "55600b3f156a0a0aeadacb1d5116500d4b64b4042f99dd052fa2dd7777c6eb0b", "class_name": "RelatedNodeInfo"}}, "text": "Figure 2.7: Original U-Net [31]\r\n\r\n### 2.3 Significance Testing\r\n\r\nThe T-test is a statistical hypothesis test used to determine if there is a significant difference between the means of two groups. It is widely used in various fields, including biomedical research, social sciences, and machine learning, to compare the performance of different models or treatments. The T-test can be classified into several types, but the most commonly used ones are the Independent Samples T-test, Paired Samples T-test, and One-Sample T-test. This section will focus on the Paired Samples T-test, which is particularly relevant when comparing the performance of two models on the same dataset.\r\n\r\n#### Significance Testing and the P-Value\r\n\r\nSignificance testing is a statistical technique used to determine whether the observed effect in data is genuine or if it could have occurred by chance. A key concept in significance testing is the p-value. The p-value is the probability of obtaining results at least as extreme as the observed results, assuming that the null hypothesis (\\(H_{0}\\)) is true. The null hypothesis typically states that there is no effect or no difference between groups.\r\n\r\nA low p-value (typically smaller than or equal to 0.05) indicates that the observed effect is unlikely to have occurred by chance, leading to the rejection of the null hypothesis. Conversely, a high p-value suggests that the observed effect could plausibly occur under the null hypothesis, and thus, the null hypothesis is not rejected. In this research, 0.05 was used as the common threshold for the judgement of significant superiority between two models regarding a performance metric.\r\n\r\n#### Paired Samples T-Test\r\n\r\nThe Paired Samples T-test, also known as the dependent T-test, is used when the samples are dependent, meaning that each pair of observations is related in some way. In the context of machine learning, this is often the case when comparing two models on the same test data, where each observation (e.g., prediction error) from one model is paired with a corresponding observation from the other model.\r\n\r\nThe Paired Samples T-test assesses whether the mean difference between these paired observations is significantly different from zero. The null hypothesis (\\(H_{0}\\)) of the test states that there is no difference between the means of the paired observations, while the alternative hypothesis (\\(H_{1}\\)) states that there is a significant difference.\r\n\r\nThe equation of the T-test is shown below:\\[t=\\frac{\\bar{d}}{s_{d}/\\sqrt{n}} \\tag{2.4}\\]\r\n\r\nwhere:\r\n\r\n* \\(\\bar{d}\\) is the mean of the differences between paired observations.\r\n* \\(s_{d}\\) is the standard deviation of the differences between paired observations.\r\n* \\(n\\) is the number of pairs.\r\n\r\nThe T-test is particularly useful because it provides a method to assess whether the observed differences between two groups are statistically significant or likely to have occurred by chance. In machine learning, it is crucial to determine if one model significantly outperforms another. The T-test offers a rigorous statistical framework for making such comparisons, ensuring that any reported improvements are not due to random variability in the data.\r\n\r\n## Chapter 3 Literature Review for Wildfire Prediction Tools\r\n\r\n### 3.1 Traditional Tools\r\n\r\nThis section introduces traditional tools that have been widely used in wildfire prediction tasks. These simulators generally incorporate spatial (multi-dimensional) and environmental (scalar, categorical label) data to model wildfire behaviour and spread. Usually, their behaviour highly relies on the quality and precision of the historical data.\r\n\r\n#### 3.1.1 Rothermel Fire Spread Equations\r\n\r\nThe Rothermel fire spread model, developed by Richard Rothermel in the 1970s [33], provides a mathematical framework for estimation of the rate of fire spread in various conditions. While Richard Rothermel developed the original model in 1972, and Frank A. Albini made notable modifications in 1976 [2], Patricia L. Andrews has furthered this work through continued research and updates [3]. Her contributions have likely involved integrating new scientific insights, improving computational methods, and adapting the model to contemporary fire management needs. This ongoing work ensures that the Rothermel model remains relevant and effective in predicting wildfire behaviour under modern conditions.", "mimetype": "text/plain", "start_char_idx": 25453, "end_char_idx": 29872, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d747e369-890d-493a-a830-49d6a831506d": {"__data__": {"id_": "d747e369-890d-493a-a830-49d6a831506d", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c41c2d5e-e431-4b0c-8cc4-064a6f9077cb", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "292d538da1797272d16b1fc6558cab9a527c165a43fda91b5c0955ba91360956", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7897a05f-6f87-43bb-bedd-657dbc79d48a", "node_type": "1", "metadata": {}, "hash": "3ac97b813bf701f9ad3c959c3fdcbc5edd4f8b301ad6156b5ca684798fbccb20", "class_name": "RelatedNodeInfo"}}, "text": "These simulators generally incorporate spatial (multi-dimensional) and environmental (scalar, categorical label) data to model wildfire behaviour and spread. Usually, their behaviour highly relies on the quality and precision of the historical data.\r\n\r\n#### 3.1.1 Rothermel Fire Spread Equations\r\n\r\nThe Rothermel fire spread model, developed by Richard Rothermel in the 1970s [33], provides a mathematical framework for estimation of the rate of fire spread in various conditions. While Richard Rothermel developed the original model in 1972, and Frank A. Albini made notable modifications in 1976 [2], Patricia L. Andrews has furthered this work through continued research and updates [3]. Her contributions have likely involved integrating new scientific insights, improving computational methods, and adapting the model to contemporary fire management needs. This ongoing work ensures that the Rothermel model remains relevant and effective in predicting wildfire behaviour under modern conditions.\r\n\r\nThe rate of fire spread \\(R\\) can be calculated using the following basic equation:\\[R=\\frac{I_{R}\\xi(1+\\phi_{w}+\\phi_{s})}{\\rho_{b}\\epsilon Q_{i}} \\tag{3.1}\\]\r\n\r\nwhere:\r\n\r\n* \\(R\\) is the rate of spread (m/min).\r\n* \\(I_{R}\\) is the reaction intensity (kW/m\\({}^{2}\\)).\r\n* \\(\\xi\\) is the propagating flux ratio.\r\n* \\(\\phi_{w}\\) is the wind coefficient.\r\n* \\(\\phi_{s}\\) is the slope coefficient.\r\n* \\(\\rho_{b}\\) is the bulk density of the fuel (kg/m\\({}^{3}\\)).\r\n* \\(\\epsilon\\) is the effective heating number.\r\n* \\(Q_{i}\\) is the heat of pre-ignition (kJ/kg).\r\n\r\nWhile the Rothermel fire spread model is widely used for its comprehensive approach, it has several limitations. One major limitation is the assumption of uniformly distributed fuel, which does not account for complex fuel arrangements in real-world scenarios. Additionally, the model does not consider changes in fuel moisture content over time or the effects of varying weather conditions beyond wind and slope. These simplifications can lead to inaccuracies in predicting fire behaviour in heterogeneous landscapes and dynamic environmental conditions.\r\n\r\n#### Fire Behavior Prediction (FBP) System\r\n\r\nThe Canadian Fire Behavior Prediction System is a framework for Canadian wildland fire behaviour prediction developed by the Canadian Forest Service in the 1980s [17]. The system was designed to provide a systematic approach to predict wildfire behaviours under various environmental conditions and help decision-making concerning fire control and other tactics. The core of the FBP system is an empirical fire spread model that was developed by analyzing fire behaviour in different Canadian forest fuels.\r\n\r\n#### Farsitte\r\n\r\nFARSITE was developed in the United States [11] and is a fire modelling system predicting the spread and behaviour of wildland fires using topography, fuel types and weather conditions. The model uses Rothermel's fire spread equations for calculating fire growth and behaviour spatially and temporally. The model outputs include fire spread rate, flame length and the shape of the fire perimeter over time, which aid firefighting strategies and management decisions. The model possesses the ability to simulate complex fire behaviours, but its performance can be limited under extreme conditions. For example, K. Zigner et al. believed FARSITE has inherent limitations on spotting algorithms when carrying out research with extreme downslope winds.\r\n\r\n#### Prometheus, Burn-P3 and Burn-P3+\r\n\r\nPrometheus is a Canadian wildfire behaviour prediction system [35] designed for the conditions of Canadian forests. The system has a similar input as FARSITE. Prometheus is based on the Canadian Fire Behavior Prediction (FBP) system but it integrates deeply with the GIS system which enables it to provide detailed simulations of fire growth with spatial and temporal changes.\r\n\r\nBurn-P3 [29] (Probabilistic Prometheus Project) integrates a probabilistic component into wildfire prediction based on Prometheus. The output of Burn-P3 includes probabilistic fire growth maps and the uncertainties of the simulation are achieved by using Monte Carlo simulation techniques. This ability enables the system to provide potential wildfire behaviour under different scenarios and support strategic planning and decision-making in firefighting.\r\n\r\nBurn-P3+ is an open-source package on SyncroSim which aims to update and replace Burn-P3. Burn-P3+ has the scalability to bigger landscapes and scenarios.", "mimetype": "text/plain", "start_char_idx": 28871, "end_char_idx": 33356, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7897a05f-6f87-43bb-bedd-657dbc79d48a": {"__data__": {"id_": "7897a05f-6f87-43bb-bedd-657dbc79d48a", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d747e369-890d-493a-a830-49d6a831506d", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "d95cb5ddb8ece29bad62fe6da10302efffba2871704c1332882b6130423f7e88", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "db1619be-4e37-4efc-8e84-5ef34eb3153f", "node_type": "1", "metadata": {}, "hash": "9c59524935b1870bc5229bd762c0cad5d8b592429988f613ccb5ea4fea1199da", "class_name": "RelatedNodeInfo"}}, "text": "#### Prometheus, Burn-P3 and Burn-P3+\r\n\r\nPrometheus is a Canadian wildfire behaviour prediction system [35] designed for the conditions of Canadian forests. The system has a similar input as FARSITE. Prometheus is based on the Canadian Fire Behavior Prediction (FBP) system but it integrates deeply with the GIS system which enables it to provide detailed simulations of fire growth with spatial and temporal changes.\r\n\r\nBurn-P3 [29] (Probabilistic Prometheus Project) integrates a probabilistic component into wildfire prediction based on Prometheus. The output of Burn-P3 includes probabilistic fire growth maps and the uncertainties of the simulation are achieved by using Monte Carlo simulation techniques. This ability enables the system to provide potential wildfire behaviour under different scenarios and support strategic planning and decision-making in firefighting.\r\n\r\nBurn-P3+ is an open-source package on SyncroSim which aims to update and replace Burn-P3. Burn-P3+ has the scalability to bigger landscapes and scenarios. By introducing good compatibility on crossing platforms and enhanced user interfaces with more detailed analytics, the tool is more accessible and effective for management and decision-making. Besides Prometheus, Burn-P3+ provides Cell2Fire as another optional model for use.\r\n\r\n### 3.2 Machine Learning Literature Review\r\n\r\nThis section introduces some past research carried out in the wildland fire field. Researchers have tried various models for fire growth prediction tasks from classic machinelearning models [25], deep learning models [37] to reinforcement learning models [14], and have brought improvement in timeliness, prediction accuracy, and adaptability to complex terrains, and changing conditions. However, the section focuses on introducing experiments involved with deep learning models, especially CNNs. Due to the similarity of tasks, fire occurrence predictions (FOP) are also included in this section.\r\n\r\n#### Machine Learning in Fire Spread Predictions\r\n\r\nJ. Hodges and B. Lattimer (2019)[18] stated that the computational cost of past models in predicting wildland fire spread across various landscapes is huge and this deeply affects the efficiency of mitigation strategies development using simulations. They proposed a Deep Convolutional Inverse Graphics Network (DCIGN) that gives an increment of computation speed by at least two orders of magnitude. The experimental data was generated by simulation tools and contained both homogeneous landscape samples and heterogeneous landscape samples with some weather input randomly generated. The former is generated by the Rothermel fire spread equations 3.1.1 and the latter is generated using FARSITE 3.1.3. They ran the DCIGN over 10 thousand times to predict fire growth after 6 to 24 hours on samples and recorded model performances in terms of precision, sensitivity, and F-measure of 0.97, 0.92, and 0.93.\r\n\r\nSince the current state-of-the-art wildfire spread models still rely on mathematical growth predictions and physics-based models, which are difficult and computationally expensive to run, Radke et al (2019) [30] presented a system named FireCast which could efficiently combine AI and GIS data. The model is trained on a large dataset augmented from real historical data and has been proven to outperform FARSITE under both wet and dry conditions on the test set regarding accuracy, recall and F-score. The author stated that FireCast outperformed modern software and is computationally inexpensive.\r\n\r\nSingh et al.(2023) [34] apply several machine-learning techniques on next-day wildfire growth predictions and they highlighted the potential of machine-learning models in such tasks. The dataset includes satellite images, weather, and geographical conditions aggregated across the United States from 2012 to 2020. In their report, all methods achieved a relatively low RMSE score while the decision tree performed the best among the three models. However, the paper does not include either highly detailed experimental results or a clear explanation of the ANN structure used for the dataset.\r\n\r\n#### Machine Learning in Fire Occurrence Predictions\r\n\r\nPrapas et al. (2021) [24] explore the application of deep learning techniques to predict daily wildfire danger. A data cube containing several features across spatial and temporal coordinates is made from historical data. The authors employed a suite of deep learning models including Random Forest, Convolutional Neural Networks, Long Short-Term Memory(LSTM), and Convolutional LSTM (ConvLSTM) that take different dimensions of the data cube and predict a next-day burned map. In the experiment result, ConvLSTM achieved the highest AUROC of 0.926, and LSTM reached the highest F1 of 0.751.", "mimetype": "text/plain", "start_char_idx": 32322, "end_char_idx": 37092, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "db1619be-4e37-4efc-8e84-5ef34eb3153f": {"__data__": {"id_": "db1619be-4e37-4efc-8e84-5ef34eb3153f", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7897a05f-6f87-43bb-bedd-657dbc79d48a", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "015132d97ad1aaf5e8cef9fb503910701ccc4e20893c4eaa761202562a71a492", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bb70fc6b-1993-4076-ad91-bb1427ee9d27", "node_type": "1", "metadata": {}, "hash": "b1221bd297b638ad46ed2da49d0874fd1c9a0d5d133dfaa9dd4837d9c715f8f9", "class_name": "RelatedNodeInfo"}}, "text": "In their report, all methods achieved a relatively low RMSE score while the decision tree performed the best among the three models. However, the paper does not include either highly detailed experimental results or a clear explanation of the ANN structure used for the dataset.\r\n\r\n#### Machine Learning in Fire Occurrence Predictions\r\n\r\nPrapas et al. (2021) [24] explore the application of deep learning techniques to predict daily wildfire danger. A data cube containing several features across spatial and temporal coordinates is made from historical data. The authors employed a suite of deep learning models including Random Forest, Convolutional Neural Networks, Long Short-Term Memory(LSTM), and Convolutional LSTM (ConvLSTM) that take different dimensions of the data cube and predict a next-day burned map. In the experiment result, ConvLSTM achieved the highest AUROC of 0.926, and LSTM reached the highest F1 of 0.751.\r\n\r\nThe need for novel wildfire warning and management tool systems is emphasized by F. Huot et al. (2020) [20] because of the growth of fire scales and the duration of fire season. The authors aggregated historical data from multiple sources into 10 feature channels and the prediction task, or \"fire likelihood estimation\" in the authors' words, is defined as three different tasks: daily image segmentation, aggregated image segmentation, and sequential aggregated image segmentation. Four different models were used in all three tasks: encoder, U-Net, encoder LSTM and U-net LSTM. Among all the performances, the autoencoder achieved the best result when performing daily segmentation and gave AUC of 0.83.\r\n\r\n#### A Review of Machine Learning Applications in Wildfire Science and Management\r\n\r\nJain et al. [22] provide a comprehensive scoping review that enhances the awareness and understanding of machine learning (ML) methods among wildfire researchers and managers. Their paper illustrates the diverse challenges in wildfire science that can be addressed using ML data science techniques, offering a thorough examination of ML applications within the field.\r\n\r\nThe review begins by outlining some widely used ML methods in wildfire science, including random forests, artificial neural networks, decision trees, support vector machines, and genetic algorithms. The authors categorized ML applications into six primary problem domains: fuels characterization, fire detection and mapping, fire weather and climate change, fire occurrence, susceptibility and risk, fire behaviour prediction, fire effects, and fire management. This categorization showcases the extensive range of wildfire-related issues that can be tackled using ML approaches.\r\n\r\nJain et al. discussed the strengths of various ML approaches, such as their ability to handle large datasets and complex relationships, making them particularly suitable forwildfire science. However, they also highlight limitations related to data size, computational requirements, generalizability, and interpretability. Despite these challenges, the authors identified significant opportunities for future research, particularly in the application of advanced ML methods like deep learning and agent-based learning. They emphasized the importance of high-quality, freely available wildfire data for developing effective ML models.\r\n\r\nIn conclusion, the paper calls for increased collaboration between wildfire researchers and ML practitioners to ensure realistic and effective modelling of fire processes. The authors stressed that the wildfire research community must actively contribute to creating relevant datasets and developing ML-based tools for wildfire science and management. By providing a detailed review of ML applications, this paper aims to improve the utilization of these methods, ultimately contributing to more effective wildfire prediction, prevention, and management strategies.\r\n\r\n## Chapter 4 Data Acquisition and Processing\r\n\r\n### 4.1 National Wildfire Dataset\r\n\r\nThis thesis studies most of the recorded wildfires that happened in Canada's national boundaries, ranging from 1994 to 2021 and across all the provinces. With reference to the architecture of current fire behaviour prediction tools and the consideration of data availability, the data set in this thesis uses 2D and 1D features coming from multiple different sources. The data was collected in different file formats, geographical coordinate systems, resolutions and time ranges, which requires appropriate pre-processing. On the one hand, it is technically not easy to acquire data at both high spatial and temporal resolution, on the other hand, some features like burned area shapes are not feasible for real-time data collection. It needs time to compute and construct from other \"raw data\". Additionally, some features for fire events are more vulnerable to natural interference. For example, when the geographical area of the occurrence of a fire event is cloudy, the heat source would not be fully observed by satellites, resulting in noise in data.", "mimetype": "text/plain", "start_char_idx": 36163, "end_char_idx": 41191, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bb70fc6b-1993-4076-ad91-bb1427ee9d27": {"__data__": {"id_": "bb70fc6b-1993-4076-ad91-bb1427ee9d27", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "db1619be-4e37-4efc-8e84-5ef34eb3153f", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "8e15fc6124e869c0badd24b12a185c557fe6f3514cea410b3ff30615062f33fa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9cfbb92d-3dd9-48c1-95a1-01a3f333969b", "node_type": "1", "metadata": {}, "hash": "d2887c7a01300a12f43739d4fa1c6d07006c5e6bd4650664130873efd90080ff", "class_name": "RelatedNodeInfo"}}, "text": "With reference to the architecture of current fire behaviour prediction tools and the consideration of data availability, the data set in this thesis uses 2D and 1D features coming from multiple different sources. The data was collected in different file formats, geographical coordinate systems, resolutions and time ranges, which requires appropriate pre-processing. On the one hand, it is technically not easy to acquire data at both high spatial and temporal resolution, on the other hand, some features like burned area shapes are not feasible for real-time data collection. It needs time to compute and construct from other \"raw data\". Additionally, some features for fire events are more vulnerable to natural interference. For example, when the geographical area of the occurrence of a fire event is cloudy, the heat source would not be fully observed by satellites, resulting in noise in data.\r\n\r\nConsidering the above reasons, the dataset used in this thesis focuses on features that are feasible to acquire in real-time or short time range, and without heavy computation. Ideally, well-processed data could help the training process and potentially provide better metrics, but also reduce the practical value of the prediction model in terms of model robustness to noise and other interference.\r\n\r\nThe boundary of Canadian provinces and territories references the shape file provided by ArcGIS hub [5], to filter data sources covering global areas. All the fire events studied in this thesis are within the total boundary shape.\r\n\r\nThe dataset consists of six 2D features and three 1D features extracted from five datasets. The daily burned area and cumulative daily burned area are computed from the National Burned Area Composite (NBAC) database [13] from the CWFIS Datamart. The fuel map comes from a dataset that is designed for Canadian Wildland Fire Information System (CWFIS) using multiple sources [4][1][12][10]. The daily Fire Weather Index (FWI) comes from the Global Fire Weather Index Dataset which is by the works of Megan M. et al. [26] and Piyush J. et al. [21]. The elevation map is acquired from the dataset published by Jeffrey N, Laurence H [23]. This dataset supports the paper presented by Laurence H. et al. regarding a high-resolution global elevation map with buildings and forests removed by machine learning techniques [16]. The three 1D features including month, fire causes and agency are from NBAC.\r\n\r\nThe size selection of the sight window (the edge length measured in meters) of each sample is determined by the statistic of burned area in the raw dataset. The distribution of the burned areas from 1994 to 2021 is shown in the kernel density estimate(KDE) chart. The KDE is a good method for visualizing the distribution of some features in a dataset. Figure 4.2 shows the complete statistic of burned area sizes in the dataset and it is obvious from the curve that some extreme values exist around the main peek. When the sight window is large enough to cover all the burned areas, it also means for the majority of the fire events, the tensor would contain a great portion of blanks. Instead, 95 percent of the densest areas in the distribution were used for the decision of sight window. The \"95 percent interval\" shown in Figure 4.3 is [552.4465, 13673.0519]. To cover those areas, a 64\\(\\times\\)64 grid with a pixel resolution of 200m is established. The max capacity for the sight\r\n\r\nFigure 4.1: Canadian provincial and territorial boundaries\r\n\r\nwindow is 16384 hectares.\r\n\r\nA sequence of procedures for data pre-processing has been performed to integrate and process every feature into the final dataset. To acquire that, a fire event dataset is constructed. Firstly, separate fire events are generated from the burned area polygon and put in the center of a bounding box. Then I mapped all the hotspots matching spatial and temporal characteristics of fire events into the bounding box and rasterized them. The rest of the features were transformed into the coordinate reference system (CRS), NAD83/Canada Atlas Lambert (geographical/projection), which is also the CRS of the burned area and hotspot dataset. After that, they are filtered according to the burning days in each fire event and masked by the bounding box. Finally, resampling is performed to align the data with 64\\(\\times\\)64 grid resolution. The procedure works well when the data is assumed to be none-sparse, integrated and without missing/noise data.", "mimetype": "text/plain", "start_char_idx": 40289, "end_char_idx": 44760, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9cfbb92d-3dd9-48c1-95a1-01a3f333969b": {"__data__": {"id_": "9cfbb92d-3dd9-48c1-95a1-01a3f333969b", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bb70fc6b-1993-4076-ad91-bb1427ee9d27", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "cfb0cdb8e9ecd305128d418f36a50bba2985fa6cc112b18cbf2f969bb341c4ca", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d8e46bbd-080a-4519-96fd-6d28df1dca74", "node_type": "1", "metadata": {}, "hash": "b5ab84eb02270d39c94e22ee83955e7898db7d6a06cb4c34db219cc141651ba4", "class_name": "RelatedNodeInfo"}}, "text": "A sequence of procedures for data pre-processing has been performed to integrate and process every feature into the final dataset. To acquire that, a fire event dataset is constructed. Firstly, separate fire events are generated from the burned area polygon and put in the center of a bounding box. Then I mapped all the hotspots matching spatial and temporal characteristics of fire events into the bounding box and rasterized them. The rest of the features were transformed into the coordinate reference system (CRS), NAD83/Canada Atlas Lambert (geographical/projection), which is also the CRS of the burned area and hotspot dataset. After that, they are filtered according to the burning days in each fire event and masked by the bounding box. Finally, resampling is performed to align the data with 64\\(\\times\\)64 grid resolution. The procedure works well when the data is assumed to be none-sparse, integrated and without missing/noise data. I addressed a few challenges when some features did not meet this assumption, and solved them using the minimum change I had to make (which are described in detail in each section). Once the fire events are built, samples are extracted from the fire events.\r\n\r\nFigure 4.2: KDE of burned areas from 1994 to 2021 with 95 percent mark\r\n\r\n### 4.2 Burned Area and Hotspot\r\n\r\nThe burned area raw dataset from NBAC contains a large shapefile of all the fire events that happened from 1994 to 2021 in the record. Each line of record stores the final burned shape of a fire in polygon/multi-polygon. This feature is not acquired by direct observation but computed from multiple data sources. Polygon-form burned area could be an ideal representation for daily fire growth but unfortunately, this is not available in daily resolution. The scale Range is from 1:5,000 Minimum to 1:150,000,000.\r\n\r\nThe burned area is useful in providing statistical information in terms of fire scales, month/year of occurrences, and provinces of occurrences. Besides that, it could be used as a limiter for the estimated daily burned area, which will be mentioned later. The limiter makes sure every generated 'ground truth' does not exceed the real fire zone.\r\n\r\nThe hotspot raw dataset from Fire M3 contains a list of shapefiles of yearly records of hotspots. The dataset aggregated multiple sources: Advanced Very High Resolution Radiometer (AVHRR) imagery, Moderate Resolution Imaging Spectroradiometer (MODIS) imagery, and Visible Infrared Imaging Radiometer Suite (VIIRS) imagery. Their resolution ranges from 30m to 1km. The satellite sensors record the intensity of electromagnetic radiation from Earth in various spectral wavelengths or channels and capture specific infrared wavelengths which are commonly emitted by fires.\r\n\r\nFigure 4.3: KDE of 95 percent burned areas from 1994 to 2021\r\n\r\n[MISSING_PAGE_FAIL:39]\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l l} \\hline \\hline Abbreviation & Description \\\\ \\hline AB & Alberta \\\\ BC & British Columbia \\\\ MB & Manitoba \\\\ NB & New Brunswick \\\\ NL & Newfoundland and Labrador \\\\ NS & Nova Scotia \\\\ NT & Northwest Territories \\\\ NU & Nunavut \\\\ ON & Ontario \\\\ PC & Parks Canada \\\\ QC & Quebec \\\\ SK & Saskatchewan \\\\ YT & Yukon Territory \\\\ \\hline \\hline \\end{tabular}\r\n\\end{table}\r\nTable 4.2: List of Abbreviations\r\n\r\n[MISSING_PAGE_EMPTY:41]\r\n\r\n[MISSING_PAGE_FAIL:42]\r\n\r\n\\[x^{\\prime} =a\\cdot x+b\\cdot y+c \\tag{4.2a}\\] \\[y^{\\prime} =d\\cdot x+e\\cdot y+f \\tag{4.2b}\\]\r\n\r\nFigure 4.4: The Bounding Box and affine transformation Matrix\r\n\r\n#### Estimated Burning Areas\r\n\r\nTo generate the daily burning area shape, I computed the convex hull from daily hotspot data in the sight windows. A convex hull of a shape is the smallest convex set that contains it. For each day in a fire event, contours were computed from discrete hotspots and transformed into a rasterized convex hull filled with 1. The method was expected to generate close enough approximate shapes of the daily burning area when the raw data was collected with limitations of resolution.\r\n\r\nThe final burned area shapes from the NBAC dataset were used as a ground truth filter on the estimation output.", "mimetype": "text/plain", "start_char_idx": 43814, "end_char_idx": 47943, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d8e46bbd-080a-4519-96fd-6d28df1dca74": {"__data__": {"id_": "d8e46bbd-080a-4519-96fd-6d28df1dca74", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9cfbb92d-3dd9-48c1-95a1-01a3f333969b", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "52ce2f4a3960bbf54ff02d3a46f5953f647e745182c11e30571a4581c6b21cf2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0f2086dc-86f2-46ee-9fc4-3d7ec65e782c", "node_type": "1", "metadata": {}, "hash": "235cc14899d9133ecae63b7f7eea15a033ca3e9463d5e3b9548dc6e49326e428", "class_name": "RelatedNodeInfo"}}, "text": "A convex hull of a shape is the smallest convex set that contains it. For each day in a fire event, contours were computed from discrete hotspots and transformed into a rasterized convex hull filled with 1. The method was expected to generate close enough approximate shapes of the daily burning area when the raw data was collected with limitations of resolution.\r\n\r\nThe final burned area shapes from the NBAC dataset were used as a ground truth filter on the estimation output. This keeps the estimation in a reasonable range and helps correct false burning at non-fuel-type locations.\r\n\r\n#### Cumulative Burning Areas\r\n\r\nThe hotspot dataset reflects the burning location during the fire event but does not provide any historical information before that time point. To assist the learning process, I added cumulative burned area shapes besides the daily burning area shapes. The extra feature provides more time-sequence information and helps the model prevent predicting burned pixels once again. As shown in figure 4.6, the images in the first row show the fire growth using estimated daily burning areas and the images in the second row show the same event using cumulative estimated burning areas.\r\n\r\nFigure 4.5: Estimated Burning Areas\r\n\r\n### 4.3 Fuel\r\n\r\nThe raw dataset of the fuel map provided a national map of Canadian FBP fuel types developed from public data sources. The map is updated to the year 2017 and is not available in high temporal resolution. In this thesis, I assumed fuel distribution does not change much and applied the fuel map of 2017 to all years from 1994 to 2021.\r\n\r\nThe raw dataset is stored in GeoTIFF format which is a rasterized data format. The empty value is filled by 65535 in the file and I changed it to 0 for the convenience of training tasks. The transformation has been carried out from its original CRS, NAD83\r\n\r\n/ Canada_Lambert_Conformal_Conic, to the target CRS. Using the bounding box acquired from the burned area, I masked the Canadian fuel map and cropped it. Finally, the rasters were resampled based on the nearest neighbour.\r\n\r\nIt is not explicitly included in the models' structure in the rest of the paper, but an embedding layer of output size 8 was used to project categorical fuel values.\r\n\r\nFigure 4.6: Cumulative Burned Areas\r\n\r\n### 4.4 Elevation\r\n\r\nThe raw Elevation dataset from FABDEM is a global elevation map available at 1 arc second grid spacing, which is approximately 30 meters. It uses WG484 as CRS and was transformed properly to the target CRS. The filling value of the elevation map was 65535, and was changed to 0.\r\n\r\nThe world map has been split into tiles with the size of 1 degree \\(\\times\\) 1 degree. This brought challenges to the searching and mapping of the feature. To tackle the problem, I computed reversely by getting a list of tiles needed from the transform of each fire event. This greatly reduced the searching time cost when there were 19011 tiles in Canada.\r\n\r\nThe complete elevation feature for each fire event came from a list of tiles. Each tile was masked, cropped, and resampled using the same transformation. Each tile contains a fragment of the required information, and I performed an XOR-like operation on all the\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l l} \\hline \\hline FBP Fuel Code & Description \\\\ \\hline\r\n1 & C1 \\\\\r\n2 & C2 \\\\\r\n3 & C3 \\\\\r\n4 & C4 \\\\\r\n5 & C5 \\\\\r\n7 & C7 \\\\\r\n11 & D1 \\\\\r\n12 & D2 \\\\\r\n13 & D1/2 \\\\\r\n31 & O1 \\\\\r\n101 & Non-fuel \\\\\r\n102 & Water \\\\\r\n106 & Urban or built-up area \\\\\r\n425 & M1 C25 \\\\\r\n525 & M2 C25 \\\\\r\n625 & M1/2 C25 \\\\\r\n635 & M1/2 C35 \\\\\r\n650 & M1/2 C50 \\\\\r\n665 & M1/2 C65 \\\\ \\hline \\hline \\end{tabular}\r\n\\end{table}\r\nTable 4.5: Canadian Forest FBP Fuel Typestransformed rasters to integrate the data. Due to the error introduced by CRS transformation and resampling, the intersection areas of tiles were likely to contain abnormal values. I performed three steps of data cleaning.", "mimetype": "text/plain", "start_char_idx": 47464, "end_char_idx": 51371, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0f2086dc-86f2-46ee-9fc4-3d7ec65e782c": {"__data__": {"id_": "0f2086dc-86f2-46ee-9fc4-3d7ec65e782c", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d8e46bbd-080a-4519-96fd-6d28df1dca74", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "92d17ad312f3ca6226cd90d81091aa9ad1a66896c2b1ad93fa5c710c7bbf81c6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c739dc1b-64af-4475-9379-553f5f429a74", "node_type": "1", "metadata": {}, "hash": "0efbed6b6d679a85a5023926e881c96307ab2e991b14920e83279a23e89b0781", "class_name": "RelatedNodeInfo"}}, "text": "Due to the error introduced by CRS transformation and resampling, the intersection areas of tiles were likely to contain abnormal values. I performed three steps of data cleaning. Pixels with NaN values, infinite values and abnormal values were replaced by the nearest neighbours in this order, where the extreme value is defined as when a pixel's elevation is over 9000(meters) or below -500(meters). There were 149 NaN values, 8 infinite values, and 534 fire events with abnormal values cleaned in this way.\r\n\r\n### 4.5 Fire Weather Index\r\n\r\nThe Fire Weather Index (FWI) raw dataset is s list of NetCDF files containing daily FWI data. It was stored in WGS84. I extracted the coordinates of each FWI record, transformed it into a geometric point, then reformatted the data into GeoDataFrame and changed the CRS.\r\n\r\nThe data is global but very sparse. A reasonable explanation for the weather-related data, the weather stations provide finite coverage. I introduced a nearest neighbour interpolation with an expanding window to solve this problem. It should be noted that advanced interpolation would perform better but considering the map is national, it could take great computation cost under high spatial resolution.\r\n\r\nFigure 4.7: Elevation from Multiple Tiles\r\n\r\nBesides a sight window, I created a sampling window which was initialized as a copy of the sight window. When there was not a valid value in the sampling window, it was expanded by a factor = 0.1, which means each side of the window extended by 0.1 of the current length to both directions. The area expansion rate was then 1.44 and it could grow to over 38 times as big as the sight window in 10 iterations. I limited the maximum number of iterations to 10 and made the algorithm take an average if multiple valid values appear in one expansion. If there was not any valid value within 10 iterations, a fire event is considered abandoned.\r\n\r\n### 4.6 Tebular(1D) Features\r\n\r\nBesides the rasterized features above, the thesis added three scalar parameters acquired along with the burned area from the NBAC database. They are agency, temporal feature and fire cause. The 1D features were integrated as a 1D array with a length of 50. The idea of introducing tabular features was inspired by the simulation setting in Burn-P3 [29] and was expected to provide a context of the fire event and help the prediction.\r\n\r\n#### Agency\r\n\r\nThe agency is a categorical feature of jurisdiction indicating which province, territory or national park a fire event was located. There are 12 labels of provinces and territories and 21 labels of national parks. The feature was stored in one-hot encoding with a length of 33.\r\n\r\n#### Temporal Feature\r\n\r\nI intended to include a temporal feature to boost the learning process. A temporal feature could be in day, month, or season. I chose months to be the temporal feature and stored it in one-hot encoding with a length of 12.\r\n\r\n#### Fire Cause\r\n\r\nThe fire cause was included in cases when potential differences exist among wildfires from different sources. This feature was also stored in one-hot encoding, which took 5 digits.\r\n\r\n\\begin{table}\r\n\\begin{tabular}{c l} \\hline \\hline\r\n**Value** & **Description** \\\\ \\hline\r\n0 & Undefined: Cause of fire unavailable \\\\\r\n1 & Other: Not covered by another category but resulting from known causes (e.g. \\\\  & \u201cmiscellaneous\u201d, \u201cincendiary\u201d) \\\\\r\n2 & Lightning: Lightning \\\\\r\n3 & Industry: e.g. forestry, oil and gas, rail, agriculture, prescribed burn \\\\\r\n4 & Human: Nonindustrial human activity, e.g. recreational (campfire, ATV, etc), arson \\\\ \\hline \\hline \\end{tabular}\r\n\\end{table}\r\nTable 4.6: Fire Cause Values and Descriptions\r\n\r\n## Chapter 5 Fusion of Heterogeneous Features\r\n\r\nStandard CNN structures often face significant challenges when it comes to integrating heterogeneous data sources, such as combining spatial (2D) data with auxiliary tabular (1D) data. The problem could be crucial when supplementary information can enhance model performance but is not easily incorporated into the standard CNN frameworks. I want a way to integrate spatial features and tabular features in the middle of U-shape networks without high dependency on the MLP. To address the problem, I introduce a novel module called Hybrid Bottleneck.", "mimetype": "text/plain", "start_char_idx": 51192, "end_char_idx": 55470, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c739dc1b-64af-4475-9379-553f5f429a74": {"__data__": {"id_": "c739dc1b-64af-4475-9379-553f5f429a74", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0f2086dc-86f2-46ee-9fc4-3d7ec65e782c", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "737adcdab8ef5c2081bdc8a1ed4b6714bf43fc9ea9576d62c5e1d56e6457ac76", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fc4fc73a-f083-4bf3-8cb6-ff3f1606b3f9", "node_type": "1", "metadata": {}, "hash": "86f10fdc530321e7aa3903d59d0858dc660cdc06f071eb6c91f103c3f2135fc2", "class_name": "RelatedNodeInfo"}}, "text": "forestry, oil and gas, rail, agriculture, prescribed burn \\\\\r\n4 & Human: Nonindustrial human activity, e.g. recreational (campfire, ATV, etc), arson \\\\ \\hline \\hline \\end{tabular}\r\n\\end{table}\r\nTable 4.6: Fire Cause Values and Descriptions\r\n\r\n## Chapter 5 Fusion of Heterogeneous Features\r\n\r\nStandard CNN structures often face significant challenges when it comes to integrating heterogeneous data sources, such as combining spatial (2D) data with auxiliary tabular (1D) data. The problem could be crucial when supplementary information can enhance model performance but is not easily incorporated into the standard CNN frameworks. I want a way to integrate spatial features and tabular features in the middle of U-shape networks without high dependency on the MLP. To address the problem, I introduce a novel module called Hybrid Bottleneck.\r\n\r\nThere are three components in U-shape networks, they are encoder, bottleneck and decoder. The encoder is a sequence of encoder blocks performing feature extraction and\r\n\r\nFigure 5.1: Hybrid Bottleneck Block in U-shape encoder-decoderrepresentation learning. The decoder is a sequence of decoder blocks performing downstream tasks. Taking U-Net as a representation of U-shape networks, a bottleneck block used in the original U-Net architecture [31] is a module with two convolutional layers that perform further feature extraction from the output of the encoder while keeping the spatial resolution of the image. I introduced a Hybrid Bottleneck Block, a bottleneck block adding this Hybrid Bottleneck in order to utilize supplementary 1D information during high-level feature extraction in the bottleneck block.\r\n\r\n### 5.1 Block Structure\r\n\r\nThe Hybrid Bottleneck block enhances the model's capability to leverage both spatial and auxiliary data effectively. It comprises four layers: A convolutional layer for compressing the size of spatial data, a concatenation layer to connect tabular and compressed spatial data, a 1x1 convolutional layer for data fusion, and a transpose convolutional layer for decompressing the data back to the same size as the input. Each convolutional layer is by default followed by a batch normalization and a RELU activation function for stable training.\r\n\r\nThe first convolutional layer is designed to take any spatial input and compress the spatial features from (H, W) to (1, 1). This procedure could be performed through more than one convolutional block but the intention was to process small internal spatial data such as (2, 2) or (4, 4). The spatial features could be considered flattened after that\r\n\r\nFigure 5.2: Hybrid Bottleneck Block\r\n\r\nbut extra dimension removal might be needed (squeezing) before the data is ready for concatenation. After concatenation, the second convolutional layer functions similarly to a fully connected layer. It uses a 1x1 kernel and restores the dimension of the input. During this step, the extra dimension brought by tabular features is compressed into the original dimensions. At last, a transposed convolutional layer restores the size of images and makes the data shape unchanged from the input. I added a residual connection to reduce the potential gradient vanishing.\r\n\r\nEmbedding the hybrid bottleneck block into U-shape networks enables the utilization of auxiliary tabular data and improves the model's performance in tasks requiring the integration of heterogeneous data sources. It keeps the data shape and thus does not introduce extra work like inserting or removing dimensions.\r\n\r\nThe hybrid bottleneck is a scalable structure since each layer in the block could be replaced by multiple layers of any size as long as the symmetry remains.\r\n\r\n### 5.2 Performance\r\n\r\nI have carried out two experimental studies of the Hybrid Bottleneck to prove the superiority of adopting it. The first study is about the advantage of utilizing tabular supplementary data in the research rather than only using spatial features. The second study is about the superiority of using a Hybrid Bottleneck structure instead of using an MLP layer during the fusion of heterogeneous data.\r\n\r\n#### Ablation study on 1D features\r\n\r\nThe ablation study was carried out on U-Net which is the baseline model in this thesis. The treatment model was trained only on five spatial features and the control model was trained on five spatial features and three tabular features with Hybrid Bottleneck (HBN).\r\n\r\nAs is shown in table 5.1, U-Net has reached an F1 score of 0.9309 which is a good performance. After applying the Hybrid Bottleneck, the F1 score of the model has achieved 0.9312.", "mimetype": "text/plain", "start_char_idx": 54628, "end_char_idx": 59215, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fc4fc73a-f083-4bf3-8cb6-ff3f1606b3f9": {"__data__": {"id_": "fc4fc73a-f083-4bf3-8cb6-ff3f1606b3f9", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c739dc1b-64af-4475-9379-553f5f429a74", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "a5dba41abc0e39d8ab3edd3de01d5b0cc2b34be03591f1f5b25fedb6b6039bf0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3aded430-9d46-4b93-801b-21fcab6a02f1", "node_type": "1", "metadata": {}, "hash": "155e7c9e0e3524af80586dc02958752e073444121474eb4156cff0895edd4790", "class_name": "RelatedNodeInfo"}}, "text": "### 5.2 Performance\r\n\r\nI have carried out two experimental studies of the Hybrid Bottleneck to prove the superiority of adopting it. The first study is about the advantage of utilizing tabular supplementary data in the research rather than only using spatial features. The second study is about the superiority of using a Hybrid Bottleneck structure instead of using an MLP layer during the fusion of heterogeneous data.\r\n\r\n#### Ablation study on 1D features\r\n\r\nThe ablation study was carried out on U-Net which is the baseline model in this thesis. The treatment model was trained only on five spatial features and the control model was trained on five spatial features and three tabular features with Hybrid Bottleneck (HBN).\r\n\r\nAs is shown in table 5.1, U-Net has reached an F1 score of 0.9309 which is a good performance. After applying the Hybrid Bottleneck, the F1 score of the model has achieved 0.9312.\r\n\r\nI carried out the T-Test on the two models and as is shown in the table 5.2, the test showed that the U-Net with the Hybrid Bottleneck is significantly better than the U-Net without the Hybrid Bottleneck, thus proving the strength of this module.\r\n\r\nThe Multilayer Perceptron (MLP) has shown high compatibility in many machine learning tasks. To prove the strength of the Hybrid Bottleneck in feature fusion, I proposed a controlled experiment. As is shown in Figure 5.3, a simplified model architecture was used for the wildfire prediction task. The architecture consists of an encoder, for which I used the encoder part in Resnet18, a feature fusion block, and the minimum combination of layers for downstream tasks.\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l l l l l l l l} \\hline Model+Data & Loss & Accuracy & Precision & Recall & Specificity & ROC AUC & PR AUC & F1 Score \\\\ \\hline U-Net & 0.088542 & 0.968302 & 0.984371 & 0.88302 & 0.995516 & 0.989216 & 0.97749 & 0.93093 \\\\ U-Net+HBN & 0.087765 & 0.968377 & 0.982626 & 0.884932 & 0.995006 & 0.9895 & 0.977889 & **0.931222** \\\\ \\hline \\end{tabular}\r\n\\end{table}\r\nTable 5.1: Performance Metrics of the Ablation Study\r\n\r\nFigure 5.3: Controlled Experiment on Resnet 18\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l l l l l} \\hline Model1 & Model2 & T-statistic & P-value & Significance \\\\ \\hline U-Net+HBN & U-Net & 2.5415 & 0.0110 & YES \\\\ \\hline \\end{tabular}\r\n\\end{table}\r\nTable 5.2: T-test on U-Net+HBN and U-NetThe implementation of the fusion block was limited to the least necessary components and did not introduce any extra computation. The first implementation using MLP consists of a flattened layer, a concatenation of hybrid features and a MLP layer. The MLP layer functions similarly to the 1x1 convolutional layer from the Hybrid Bottleneck, which adjusts the size of data. The second implementation uses the Hybrid Bottleneck and has the same output size as the first implementation method.\r\n\r\nAs is shown in table 5.3, with finite feature extraction of a simpler encoder, The Hybrid Bottleneck has shown strength against MLP implementation on utilizing supplementary data. The model using a Hybrid Bottleneck showed an absolute superiority on every metric, especially more than 2% higher on the F1 score.\r\n\r\n#### Experimental Result Analysis\r\n\r\nThe ablation study of the Hybrid Bottleneck revealed the effectiveness of introducing hybrid features over single features in the prediction task on the best network structure I proposed in the thesis. However, due to the strong ability in feature extraction of the best neural network, the performance increment is noticeable but small. In the controlled experiment carried out on the Resnet18 encoder, I focused on the function of the fusion module and suppressed the rest parts in the model. The matrices proved the strength of the Hybrid Bottleneck in utilizing supplementary data when it could greatly assist the learning process of downstream tasks.", "mimetype": "text/plain", "start_char_idx": 58305, "end_char_idx": 62173, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3aded430-9d46-4b93-801b-21fcab6a02f1": {"__data__": {"id_": "3aded430-9d46-4b93-801b-21fcab6a02f1", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fc4fc73a-f083-4bf3-8cb6-ff3f1606b3f9", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "cceb87acf41b4eeb23bbac072c60983ce9d244714ad8a082e1e966c499f5fff7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fbe9d181-82dc-4f7b-afc0-ab6992f62233", "node_type": "1", "metadata": {}, "hash": "04fc81c86b8ef007ade11e523afea896f9d6144b70c7a00e165979634a0a62f2", "class_name": "RelatedNodeInfo"}}, "text": "As is shown in table 5.3, with finite feature extraction of a simpler encoder, The Hybrid Bottleneck has shown strength against MLP implementation on utilizing supplementary data. The model using a Hybrid Bottleneck showed an absolute superiority on every metric, especially more than 2% higher on the F1 score.\r\n\r\n#### Experimental Result Analysis\r\n\r\nThe ablation study of the Hybrid Bottleneck revealed the effectiveness of introducing hybrid features over single features in the prediction task on the best network structure I proposed in the thesis. However, due to the strong ability in feature extraction of the best neural network, the performance increment is noticeable but small. In the controlled experiment carried out on the Resnet18 encoder, I focused on the function of the fusion module and suppressed the rest parts in the model. The matrices proved the strength of the Hybrid Bottleneck in utilizing supplementary data when it could greatly assist the learning process of downstream tasks.\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l r r r r r r r} \\hline \\hline Model+Fusion Method & Loss & Accuracy & Precision & Recall & Specificity & ROC AUC & PR AUC & F1 Score \\\\ \\hline Resnet18+HBN & 0.122746 & 0.957954 & 0.941683 & 0.880842 & 0.982561 & 0.982799 & 0.965945 & 0.910203 \\\\ REsnet18+MLP & 0.147394 & 0.944312 & 0.895637 & 0.871437 & 0.967567 & 0.979975 & 0.952931 & 0.883328 \\\\ \\hline \\hline \\end{tabular}\r\n\\end{table}\r\nTable 5.3: Perfomance Metrices of the Controlled Experiment\r\n\r\n## Chapter 6 Burned Area Prediction\r\n\r\nThis chapter elucidates the design of the next-day burned area prediction task, the model used, and the experimental result. I reproduced three deep-learning models from the existing literature reviews and then researched U-Net to seek better solutions. Extending from U-Net, I assessed the convolution and attention mechanism by testing two variants of the original U-Net.\r\n\r\nSimilar to the ablation study conducted in the last chapter, for any model that utilizes the HBN module in this chapter (the U-shape models since section 6.3), the metrics table recording model performances will include both models with HBN and models without HBN. When the name of a model is mentioned in a paragraph, it stands for the model with HBN structure in default (\"model without the HBN structure\" stated otherwise). When without the HBN structure, the model only takes spatial input.\r\n\r\n### 6.1 Experiment Design\r\n\r\n#### Hyperparameters\r\n\r\nThe hyperparameters for my model were carefully selected through a combination of grid search and empirical testing.\r\n\r\n* **Learning Rate:** The learning rate was set to \\(\\alpha=0.001\\), chosen to balance the trade-off between convergence speed and stability.\r\n* **Batch Size:** A batch size of 32 was used to ensure efficient utilization of GPU memory while maintaining a stable training process.\r\n\r\n* **Number of Epochs:** The model was trained for 30 epochs, with early stopping criteria based on validation loss to prevent overfitting.\r\n* **K-Fold Cross-Validation:** To ensure robust evaluation, I employed 5-fold cross-validation. This approach helps in assessing the model's generalization ability and mitigating overfitting.\r\n\r\n#### Loss\r\n\r\nBinary Cross Entropy Loss (BCELoss) was selected to measure the performance of my binary classification/segmentation model.\r\n\r\n\\[\\mathcal{L}_{\\text{BCE}}(y,\\hat{y})=-\\frac{1}{N}\\sum_{i=1}^{N}\\left[y_{i}\\log( \\hat{y}_{i})+(1-y_{i})\\log(1-\\hat{y}_{i})\\right] \\tag{6.1}\\]\r\n\r\nwhere:\r\n\r\n* \\(y_{i}\\) represents the true label for the \\(i\\)-th sample, indicating whether a fire occurred (\\(y_{i}=1\\)) or not (\\(y_{i}=0\\)).\r\n* \\(\\hat{y}_{i}\\) represents the predicted probability of fire occurrence for the \\(i\\)-th sample.\r\n* \\(N\\) is the total number of samples.", "mimetype": "text/plain", "start_char_idx": 61166, "end_char_idx": 64938, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fbe9d181-82dc-4f7b-afc0-ab6992f62233": {"__data__": {"id_": "fbe9d181-82dc-4f7b-afc0-ab6992f62233", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3aded430-9d46-4b93-801b-21fcab6a02f1", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "30cebe2b4be534c688a2e9cd759106b8ebff148fda35bb2903ad621f9831af11", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "20ad84dd-9d5f-48ba-95ee-b537b6201223", "node_type": "1", "metadata": {}, "hash": "ce0bb3852f56cb42b56fc97d5c2c096f54a3e1de84fa5eb263f5496e1c6cbd0b", "class_name": "RelatedNodeInfo"}}, "text": "#### Loss\r\n\r\nBinary Cross Entropy Loss (BCELoss) was selected to measure the performance of my binary classification/segmentation model.\r\n\r\n\\[\\mathcal{L}_{\\text{BCE}}(y,\\hat{y})=-\\frac{1}{N}\\sum_{i=1}^{N}\\left[y_{i}\\log( \\hat{y}_{i})+(1-y_{i})\\log(1-\\hat{y}_{i})\\right] \\tag{6.1}\\]\r\n\r\nwhere:\r\n\r\n* \\(y_{i}\\) represents the true label for the \\(i\\)-th sample, indicating whether a fire occurred (\\(y_{i}=1\\)) or not (\\(y_{i}=0\\)).\r\n* \\(\\hat{y}_{i}\\) represents the predicted probability of fire occurrence for the \\(i\\)-th sample.\r\n* \\(N\\) is the total number of samples.\r\n\r\nThe advantages of using the BCE loss function in wildfire spread prediction include its effectiveness in handling imbalanced datasets by focusing on the prediction probability for each class, providing a smooth gradient which facilitates the training of deep learning models, and its direct relation to probabilistic outputs, making it suitable for binary classification tasks such as predicting fire spread probability on pixels.\r\n\r\n#### Optimizers\r\n\r\nThe AdamW optimizer was chosen due to its adaptive learning rate capabilities and the added benefit of weight decay regularization. The weight decay parameter was set to 0.0001.\r\n\r\n#### Evaluation Metrics\r\n\r\nTo assess the performance of my model, I used the following evaluation metrics:\r\n\r\n* **Accuracy:** This metric measures the proportion of correct predictions.\r\n* **Precision:** Precision evaluates the number of true positive predictions made out of all positive predictions.\r\n* **Recall:** Recall measures the number of true positive predictions made out of all actual positives.\r\n* **Specificity:** Specificity assesses the number of true negative predictions made out of all actual negatives.\r\n* **ROC AUC:** The Receiver Operating Characteristic Area Under the Curve (ROC AUC) provides a measure of the model's ability to distinguish between classes.\r\n* **PR AUC:** The Precision-Recall Area Under the Curve (PR AUC) is used to evaluate the trade-off between precision and recall.\r\n* **F1 Score:** The F1 score, which is the harmonic mean of precision and recall, was used as the main metric for evaluation.\r\n\r\n#### Additional Settings\r\n\r\nOther important settings and configurations include:\r\n\r\n* **Data Preprocessing:** The data was standardized using the statistical standard deviation and mean of the train set. The same standardization was applied to the train set and test set.\r\n* **Hardware and Software:** The experiments were conducted on a NVIDIA GeForce RTX 4090 Laptop GPU, with the implementation done in Python using the Pytorch libraries.\r\n* **Early Stopping:** Early stopping was applied in all training processes. The model with the lowest validation loss during all epochs was selected in each fold to prevent overfitting and ensure optimal performance on the test.\r\n\r\n### 6.2 Past Work Reproduction\r\n\r\n#### Ann\r\n\r\nSingh et al.(2023) [34] voted the existence of research gaps in wildfire growth prediction and attempted to prove the practical value of deep learning algorithms through an Artificial Neural Network(ANN) structure.\r\n\r\nThe dataset in their research has a highly similar specification to the dataset in this thesis. The ANN model was designed for layers of 64\\(\\times\\)64 spatial features with a pixel resolution of 1km. However, the paper lacks detailed level information on the model and the data flow. The block chart regarding model structure seems to be unfit for the input data. The largest layer in their model is a fully connected layer with 128 neurons which is a relatively small amount even compared to the number of pixels in a single spatial feature (64\\(\\times\\)64). Additionally, the authors did not mention much about the reshaping operations during their experiment which brought difficulty in reproduction.\r\n\r\nWith the missing information, I have added the least change necessary to fit the model with my data, which includes flattening and concatenation of the input, an extra fully connected layer for outputting prediction, and reshaping. The entire model consists of four blocks. Each block is a combination of a fully connected layer, an activation function, and a dropout layer except the last block which only has a fully connected layer.", "mimetype": "text/plain", "start_char_idx": 64369, "end_char_idx": 68599, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "20ad84dd-9d5f-48ba-95ee-b537b6201223": {"__data__": {"id_": "20ad84dd-9d5f-48ba-95ee-b537b6201223", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fbe9d181-82dc-4f7b-afc0-ab6992f62233", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "bfec7ade0f60eaa212f8dbdcee7fcd8dbf6ca0ebfc84e951f81abd327f578f83", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7a3971e3-1676-4996-8aec-f0b2bee55abc", "node_type": "1", "metadata": {}, "hash": "c882e8b408d2dcac6e356ac616a6d5273227b63cfa8d6d1887bfd2b4848c2f5e", "class_name": "RelatedNodeInfo"}}, "text": "However, the paper lacks detailed level information on the model and the data flow. The block chart regarding model structure seems to be unfit for the input data. The largest layer in their model is a fully connected layer with 128 neurons which is a relatively small amount even compared to the number of pixels in a single spatial feature (64\\(\\times\\)64). Additionally, the authors did not mention much about the reshaping operations during their experiment which brought difficulty in reproduction.\r\n\r\nWith the missing information, I have added the least change necessary to fit the model with my data, which includes flattening and concatenation of the input, an extra fully connected layer for outputting prediction, and reshaping. The entire model consists of four blocks. Each block is a combination of a fully connected layer, an activation function, and a dropout layer except the last block which only has a fully connected layer.\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l l l l l} \\hline \\hline Block & Layer & Parameters & Input Size & Output Size \\\\ \\hline\r\n1 & Linear & & 12\\(\\times 64^{2}+50\\) & 128 \\\\\r\n1 & RELU & & & \\\\\r\n1 & Dropout & p=0.5 & & \\\\\r\n2 & Linear & & 128 & 64 \\\\\r\n2 & RELU & & & \\\\\r\n2 & Dropout & p=0.5 & & \\\\\r\n3 & Linear & & 64 & 32 \\\\\r\n3 & RELU & & & \\\\\r\n3 & Dropout & p=0.5 & & \\\\\r\n4 & Linear & & 32 & 64\\({}^{2}\\) \\\\ \\hline \\hline \\end{tabular}\r\n\\end{table}\r\nTable 6.1: ANN\r\n\r\n#### Dcign\r\n\r\nThe Deep convolutional inverse graphics network (DCIGN) was proposed by J. Hodges and B. Lattimer. [18] The model was proposed as an efficient prediction model competing with traditional models regarding both time and computation cost, especially in heterogeneous landscapes with complex terrain.\r\n\r\nThe DCIGN is an encoder-decoder convolutional model. It was designed for 13 channels of 50\\(\\times\\)50 spatial features and outputs two layers. I have changed the minimum arguments to fit the model with my data. The authors of the DCIGN added a dropout rate of 0.5 at the input layer to reduce the over-fitting problem. The feature extraction happened in two convolution blocks, which used a relatively uncommon large kernel with half padding. Similar to traditional CNN, a fully connected layer was added for downstream tasks. In the original network structure, the output was 2 layers of images. An additional transposed convolutional layer was inserted to compress the shape of the output.\r\n\r\nThere are two main reasons I did not apply the Hybrid Bottleneck in the DCIGN. The first reason is I did not intend to introduce much modification while a concatenation at the fully connected layer could do its job. The second reason is that the DCIGN did not compress the image size enough and it could bring a great portion of extra computation. The Hybrid Bottleneck intends to create a lightweight component possessing the functionality of feature fusion.", "mimetype": "text/plain", "start_char_idx": 67657, "end_char_idx": 70533, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7a3971e3-1676-4996-8aec-f0b2bee55abc": {"__data__": {"id_": "7a3971e3-1676-4996-8aec-f0b2bee55abc", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "20ad84dd-9d5f-48ba-95ee-b537b6201223", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "e1da4653ffc230b9902b08acbbabf0c64c57c3e1f42fe3f2d560191de757d727", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "004921a2-cad6-416c-9b4d-580d8208d508", "node_type": "1", "metadata": {}, "hash": "ac2a5c19938d6c725017211fba273e14bcf42d3bdb014a7e0806de147f5888be", "class_name": "RelatedNodeInfo"}}, "text": "The authors of the DCIGN added a dropout rate of 0.5 at the input layer to reduce the over-fitting problem. The feature extraction happened in two convolution blocks, which used a relatively uncommon large kernel with half padding. Similar to traditional CNN, a fully connected layer was added for downstream tasks. In the original network structure, the output was 2 layers of images. An additional transposed convolutional layer was inserted to compress the shape of the output.\r\n\r\nThere are two main reasons I did not apply the Hybrid Bottleneck in the DCIGN. The first reason is I did not intend to introduce much modification while a concatenation at the fully connected layer could do its job. The second reason is that the DCIGN did not compress the image size enough and it could bring a great portion of extra computation. The Hybrid Bottleneck intends to create a lightweight component possessing the functionality of feature fusion.\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l l l l l} \\hline Block & Layer & Parameters & Input Size & Output Size \\\\ \\hline\r\n0 & Dropout & p=0.5 & & \\\\\r\n1 & Conv2d & k=10 s=1 p=half & (12, 64, 64) & (32, 64, 64) \\\\\r\n1 & RELU & & & \\\\\r\n1 & MaxPool2d & k=2 s=2 & (32, 64, 64) & (32, 32, 32) \\\\\r\n2 & Conv2d & k=3 s=1 p=half & (32, 32, 32) & (64, 32, 32) \\\\\r\n2 & RELU & & & \\\\\r\n2 & MaxPool2d & k=2 s=2 & (64, 32, 32) & (64, 16, 16) \\\\\r\n3 & Linear & & & 64\\(\\times\\)16\\({}^{2}\\) & 2\\(\\times\\)64\\({}^{2}\\) \\\\\r\n3 & Tanh & & & \\\\\r\n3 & ConvTranspose2d & k=10 s=1 p=half & (2, 64, 64) & (1, 64, 64) \\\\ \\hline \\end{tabular}\r\n\\end{table}\r\nTable 6.2: DCIGN\r\n\r\n#### FireCast\r\n\r\nThe FireCast model was proposed by Radke et al (2019) [30] is another deep-learning tool aiming to compete with the commonly used traditional fire prediction models. The model has been proven to outperform random prediction and FARSITE on their dataset. Since the model already includes fully connected layers, we performed concatenation as data fusion on the second fully connected layer directly.\r\n\r\nThe FireCast is a traditional CNN model using an encoder-decoder structure. In the encoder part, convolutional layers and pooling layers compress image size and fully connected layers perform downstream tasks. Two fully connected layers were inserted in the decoder and the data fusion happened between two layers by concatenation. The modified model inherited the original design but changed the size of the layers.\r\n\r\n#### Experimental Result and Analysis\r\n\r\nAmong the three reproduced models. FireCast reached the best performance overall and was superior to the other two according to the table. The ANN model gave moderate performance and seemed to be not very compatible with the dataset when I used the same image sizes as their research. It reached an accuracy score of less than 90 percent. In terms of F1 score, it had a gap greater than 15 percent to the DCIGN, and a gap greater than 25 percent to the FireCast.", "mimetype": "text/plain", "start_char_idx": 69590, "end_char_idx": 72515, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "004921a2-cad6-416c-9b4d-580d8208d508": {"__data__": {"id_": "004921a2-cad6-416c-9b4d-580d8208d508", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7a3971e3-1676-4996-8aec-f0b2bee55abc", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "0a9307db46fcbad5ab494b42a35ae1dd0b2559de73ec76268c34eba6e6d38b07", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "db000a10-c025-473f-bc19-bf9d0fbee47c", "node_type": "1", "metadata": {}, "hash": "e344ad0cbb4ef289000af45ed56b78d778b3ec799de4dae378391d7971c63320", "class_name": "RelatedNodeInfo"}}, "text": "The FireCast is a traditional CNN model using an encoder-decoder structure. In the encoder part, convolutional layers and pooling layers compress image size and fully connected layers perform downstream tasks. Two fully connected layers were inserted in the decoder and the data fusion happened between two layers by concatenation. The modified model inherited the original design but changed the size of the layers.\r\n\r\n#### Experimental Result and Analysis\r\n\r\nAmong the three reproduced models. FireCast reached the best performance overall and was superior to the other two according to the table. The ANN model gave moderate performance and seemed to be not very compatible with the dataset when I used the same image sizes as their research. It reached an accuracy score of less than 90 percent. In terms of F1 score, it had a gap greater than 15 percent to the DCIGN, and a gap greater than 25 percent to the FireCast. This reflects the limited capabilities of this model on\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l l l l l} \\hline Block & Layer & Parameters & Input Size & Output Size \\\\ \\hline\r\n0 & AvgPool & k=2 s=2 & (32, 64, 64) & (32, 32, 32) \\\\\r\n1 & Conv2d & k=3 s=2 p=1 & (32, 32, 32) & (32, 16, 16) \\\\\r\n1 & Sigmoid & & & \\\\\r\n1 & MaxPool2d & k=2 s=2 & (32, 16, 16) & (32, 8, 8) \\\\\r\n1 & Dropout & p=0.5 & & \\\\\r\n2 & Conv2d & k=3 s=2 p=1 & (32, 8, 8) & (64, 4, 4) \\\\\r\n2 & Sigmoid & & & \\\\\r\n2 & MaxPool2d & k=2 s=2 & (64, 4, 4) & (64, 2, 2) \\\\\r\n2 & Dropout & p=0.5 & & \\\\\r\n3 & Linear & & 64\\(\\times 2^{2}\\) & 128\\(\\times 2^{2}\\) \\\\\r\n3 & Linear & & 128\\(\\times 2^{2}+50\\) & 64\\(\\times 64\\) \\\\ \\hline \\end{tabular}\r\n\\end{table}\r\nTable 6.3: FireCastan unbalanced dataset. The limitation could come from the scale of the model and the pure composition of fully connected layers in the structure. DCIGN showed an improved performance compared to the ANN model. The accuracy of DCIGN has reached 90.06% and the F1 score has reached 75.63%. The FireCast outperformed the other two models and achieved an accuracy score of 93.24%. A gap of over 10% on the F1 score compared to the second model showed a better balance between positive and negative pixel classification.\r\n\r\n### 6.3 Comparing Convolutional U-Shape Networks and Attention-Based U-Shape Networks\r\n\r\nIn this section, I delve into a comparative analysis of convolutional U-shape networks and attention-based U-shape networks by experimenting with U-Net, U-Net3+, and SwinUNet. The objective is to understand how these different architectures perform in the context of image segmentation, particularly in predicting wildfire growth.\r\n\r\nU-Net serves as the baseline model in this analysis, providing a foundation to confirm the efficiency of the U-shape structure for the given task. U-Net3+ and SwinUNet represent two advanced extensions of this architecture, incorporating different mechanisms to enhance performance. U-Net3+ builds upon the traditional convolutional approach by adding deeper supervision and additional skip pathways, aiming to improve segmentation accuracy and robustness. SwinUNet, on the other hand, integrates self-attention mechanisms, enabling the model to dynamically focus on relevant features across the spatial dimensions of the image. Through the study of these two extensions, I hoped to explore the possibility of improvement on the baseline model.\r\n\r\n#### U-Net\r\n\r\nU-Net is a type of Convolutional Neural Network (CNN) invented by Olaf Ronneberger et al. in 2015.", "mimetype": "text/plain", "start_char_idx": 71592, "end_char_idx": 75044, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "db000a10-c025-473f-bc19-bf9d0fbee47c": {"__data__": {"id_": "db000a10-c025-473f-bc19-bf9d0fbee47c", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "004921a2-cad6-416c-9b4d-580d8208d508", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "a4b3c48c3bf1bb03b895f170d500bf0c7e6ca0ed981cec2630703472887fea65", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3e14b145-f2ed-4771-990d-ed6d8b43463d", "node_type": "1", "metadata": {}, "hash": "d26b8794ad08cd28bcd212f63b917bb605f68ff428e66391073681a4c7e449dd", "class_name": "RelatedNodeInfo"}}, "text": "U-Net serves as the baseline model in this analysis, providing a foundation to confirm the efficiency of the U-shape structure for the given task. U-Net3+ and SwinUNet represent two advanced extensions of this architecture, incorporating different mechanisms to enhance performance. U-Net3+ builds upon the traditional convolutional approach by adding deeper supervision and additional skip pathways, aiming to improve segmentation accuracy and robustness. SwinUNet, on the other hand, integrates self-attention mechanisms, enabling the model to dynamically focus on relevant features across the spatial dimensions of the image. Through the study of these two extensions, I hoped to explore the possibility of improvement on the baseline model.\r\n\r\n#### U-Net\r\n\r\nU-Net is a type of Convolutional Neural Network (CNN) invented by Olaf Ronneberger et al. in 2015. [31] It was primarily designed for biomedical image segmentation but has since\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l c c c c c c c} \\hline Model & Loss & Accuracy & Precision & Recall & Specificity & ROC AUC & PR AUC & F1 Score \\\\ \\hline ANN & 0.3616 & 0.8334 & 0.692119 & 0.531867 & 0.929622 & 0.869662 & 0.678822 & 0.584773 \\\\ DCIGN & 0.254213 & 0.900614 & 0.832601 & 0.721183 & 0.957872 & 0.918157 & 0.819351 & 0.756338 \\\\ FireCast & 0.180651 & 0.932399 & 0.878606 & 0.836151 & 0.963113 & 0.970856 & 0.927653 & 0.856813 \\\\ \\hline \\end{tabular}\r\n\\end{table}\r\nTable 6.4: Performance Metrics for Reproduced Modelsfound applications in various fields requiring precise localization and context understanding. By leveraging its ability to capture intricate details and contextual information from spatial data, U-Net can process satellite imagery and other geospatial inputs to forecast the spread of wildfires.\r\n\r\nThe U-Net structure in this thesis was a modification based on the original U-Net design proposed by the authors [31]. From the functional perspective, This U-Net consists of an encoder, a Hybrid Bottleneck, and a decoder. From the perspective of image shapes, each half of the U-Net contains four convolutional blocks at four levels. There are three components in each block. The first convolutional layer adjusts the size of channels, and the second convolutional layer extracts features without changing the shape of the data, then the last layer adjusts the spatial dimensions and sends it to the next layer. The independence among different functional components benefits the modification of the network structure. The bottleneck block in the original U-Net contains two convolutional layers. I assigned them to encoder and decoder separately, then inserted the Hybrid Bottleneck structure between two layers, renaming them the Hybrid Bottleneck block. I added a transposed convolutional layer in addition to the original U-Net to generate a 64\\(\\times\\)64 probability map of the next day's burned area. The skip connection combines low-level and high-level features along with the decoder.\r\n\r\nFigure 6.1: U-Net+HBN Structure\r\n\r\nThe metrics of the experiment were already shown in the table 5.1. The U-Net model exhibits exceptional performance with a loss of 0.087765, indicating high prediction accuracy. It achieved an accuracy of 96.84%, precision of 98.26%, and recall of 88.49%, demonstrating its effectiveness in identifying both positive and negative cases. The specificity of 99.50% and high ROC AUC (98.95%) and PR AUC (97.79%) further confirms its robustness. The F1 score of 93.12% highlights U-Net's balanced performance, making it promising for precise and accurate wildfire spread prediction.\r\n\r\nThrough the loss curve during the training process, the U-net tended to overfit the dataset after approximately 12 epochs. The train loss kept going down while the validation loss went up. This was well controlled by the early-stop strategy based on the validation records.", "mimetype": "text/plain", "start_char_idx": 74184, "end_char_idx": 78045, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3e14b145-f2ed-4771-990d-ed6d8b43463d": {"__data__": {"id_": "3e14b145-f2ed-4771-990d-ed6d8b43463d", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "db000a10-c025-473f-bc19-bf9d0fbee47c", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1c851bbc35ab642570ff8c33fda40463b8e6b459d8094ddb6beb2f79749543bf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9e2e718d-668d-4466-b854-8ac72f90b1d5", "node_type": "1", "metadata": {}, "hash": "5d6b4b14ce28e1b3ab2965aad45c503a72dbee218a998b6b3bb1b997ee3a9dff", "class_name": "RelatedNodeInfo"}}, "text": "The U-Net model exhibits exceptional performance with a loss of 0.087765, indicating high prediction accuracy. It achieved an accuracy of 96.84%, precision of 98.26%, and recall of 88.49%, demonstrating its effectiveness in identifying both positive and negative cases. The specificity of 99.50% and high ROC AUC (98.95%) and PR AUC (97.79%) further confirms its robustness. The F1 score of 93.12% highlights U-Net's balanced performance, making it promising for precise and accurate wildfire spread prediction.\r\n\r\nThrough the loss curve during the training process, the U-net tended to overfit the dataset after approximately 12 epochs. The train loss kept going down while the validation loss went up. This was well controlled by the early-stop strategy based on the validation records.\r\n\r\n#### Extensions\r\n\r\n#### U-Net 3+\r\n\r\nU-Net3+ is an advanced variant of the traditional U-Net architecture designed to enhance performance in image segmentation tasks. [19] One of the key innovations in U-Net3+ is its approach to aggregating multi-scale feature maps at each level of the decoder.\r\n\r\nFigure 6.2: 5-fold loss curve of U-Net\r\n\r\n\\[X_{De}^{i}=\\begin{cases}X_{En}^{i},&i=N\\\\ \\mathcal{H}\\left(\\left[\\underbrace{C\\left(\\mathcal{D}\\left(X_{En}^{k}\\right) \\right)_{k=1}^{i-1}C\\left(X_{En}^{i}\\right)}_{\\text{Scales: 1${}^{th}\\sim i ${}^{th}}},\\underbrace{C\\left(U\\left(X_{De}^{k}\\right)\\right)_{k=i+1}^{N}}_{ \\text{Scales: ($i+1$)}^{th}\\sim N^{th}}\\right]\\right),&i=1,\\cdots,N-1\\end{cases} \\tag{6.2}\\]\r\n\r\nIn this equation, \\(X_{de}^{i}\\) represents the feature map at the \\(i\\)-th level of the decoder, while \\(X_{en}^{i}\\) denotes the feature map from the corresponding encoder level. In this thesis, N=5 where the fifth level stands for the bottleneck block. If treating the bottleneck block as a whole entity, there would be only one computation happening at this level thus \\(X_{De}^{i}=X_{En}^{i}\\) when \\(i=N\\). For other levels (\\(i=1,\\cdots,N-1\\)), the decoder feature map \\(X_{de}^{i}\\) is obtained by concatenating the downsampled feature maps from the encoder at all preceding scales (\\(1^{\\text{st}}\\sim i^{th}\\)), the feature map from the current encoder level \\(X_{en}^{i}\\), and the upsampled feature maps from the decoder at all subsequent scales (\\((i+1)^{th}\\sim N^{th}\\)). This concatenated stack is then processed by a function \\(\\mathcal{H}\\), which is a convolutional layer with a 1\\(\\times\\)1 kernel in this research. This dense concatenation approach ensures that each decoding layer benefits from both fine-grained details and high-level contextual information, enhancing the model's ability to produce accurate and detailed segmentation outputs.\r\n\r\n#### Swin-Unet\r\n\r\nSwin-UNet is a novel variant of the U-Net architecture that integrates Swin Transformers to enhance image segmentation performance. [7] Unlike traditional convolution-based U\r\n\r\nFigure 6.3: Feature aggregation on \\(X_{de}^{2}\\) in U-Net 3+\r\n\r\nNet models, Swin-UNet leverages the power of self-attention mechanisms provided by Swin Transformers. This allows the model to dynamically capture and focus on relevant features across various spatial dimensions of the input image.", "mimetype": "text/plain", "start_char_idx": 77257, "end_char_idx": 80421, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9e2e718d-668d-4466-b854-8ac72f90b1d5": {"__data__": {"id_": "9e2e718d-668d-4466-b854-8ac72f90b1d5", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3e14b145-f2ed-4771-990d-ed6d8b43463d", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "7f56a77f0a25896a7895c13b3899eca7bd355200a543fa1f4d8a83bbbacedda3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f460512b-c36c-490d-946f-ff954d410605", "node_type": "1", "metadata": {}, "hash": "6d6507f5a9a71364cdda4f257dcb502e166554a21c0e3df6f5be5e98cc1017b3", "class_name": "RelatedNodeInfo"}}, "text": "This concatenated stack is then processed by a function \\(\\mathcal{H}\\), which is a convolutional layer with a 1\\(\\times\\)1 kernel in this research. This dense concatenation approach ensures that each decoding layer benefits from both fine-grained details and high-level contextual information, enhancing the model's ability to produce accurate and detailed segmentation outputs.\r\n\r\n#### Swin-Unet\r\n\r\nSwin-UNet is a novel variant of the U-Net architecture that integrates Swin Transformers to enhance image segmentation performance. [7] Unlike traditional convolution-based U\r\n\r\nFigure 6.3: Feature aggregation on \\(X_{de}^{2}\\) in U-Net 3+\r\n\r\nNet models, Swin-UNet leverages the power of self-attention mechanisms provided by Swin Transformers. This allows the model to dynamically capture and focus on relevant features across various spatial dimensions of the input image.\r\n\r\n\\[\\begin{split}\\hat{z}^{l}=W-MSA\\left(LN\\left(z^{l-1}\\right)\\right)+z^{l- 1}\\\\ z^{l}=MLP\\left(LN\\left(\\hat{z}^{l}\\right)\\right)+\\hat{z}^{l}\\\\ \\hat{z}^{l+1}=SW-MSA\\left(LN\\left(z^{l}\\right)\\right)+z^{l}\\\\ z^{l+1}=MLP\\left(LN\\left(\\hat{z}^{l+1}\\right)\\right)+\\hat{z}^{l+1} \\end{split} \\tag{6.3}\\]\r\n\r\nSwin-UNet replaces each regular convolutional block in the U-Net structure with two consecutive windowed multi-head self-attention blocks. For each pair of consecutive blocks at the same level, the first multi-head self-attention block divides the input image into non-overlapping windows and performs self-attention within each window independently. To enhance the model's ability to capture long-range dependencies across different regions of the image the second windows are shifted by a fixed number of pixels, and self-attention is performed again. This shifting mechanism is called shifted windowed multi-head self-attention. It ensures that the attention computation spans across the boundaries of the original windows, allowing the model to learn relationships between distant parts of the image.\r\n\r\nFigure 6.4: Swin Transformer Block [7]\r\n\r\n#### Experimental Result\r\n\r\nThe analysis (table 6.5) shows that while all three models perform exceptionally well, U-Net3+ slightly outperforms the others when considering the F1 score. This indicates that the enhancements in U-Net3+, such as the addition of deeper supervision and more extensive skip connections, provide a meaningful improvement over the original U-Net. SwinUNet, despite its innovative use of self-attention mechanisms, falls slightly behind in terms of F1 score due to its lower recall, suggesting it might be less effective in capturing all true positives in the dataset.\r\n\r\nThe convolutional network models tend to overfit the data but early-stop effectively prevented it and kept the generalization of the models. The loss score of Swin-Unet shows a larger fluctuation compared to the other two models. Instead of a smooth decrease, it oscillates but converges better than the other two models. A slight over-fitting can still be observed, but the Swin-Unet has shown its advantage in training convergence and stability, which is probably due to the regularization in the structure.", "mimetype": "text/plain", "start_char_idx": 79546, "end_char_idx": 82679, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f460512b-c36c-490d-946f-ff954d410605": {"__data__": {"id_": "f460512b-c36c-490d-946f-ff954d410605", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9e2e718d-668d-4466-b854-8ac72f90b1d5", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "b58a95a4af057c17f8effd4a0330e7b0a3b174629b9860bb4844c064cf15dc9c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c6948006-a008-4953-be8c-72810d5a10ae", "node_type": "1", "metadata": {}, "hash": "0df0bbcca7b108aac0d7c30bd7f1d35406dafd6f839664eccbbacd324e4382ba", "class_name": "RelatedNodeInfo"}}, "text": "This indicates that the enhancements in U-Net3+, such as the addition of deeper supervision and more extensive skip connections, provide a meaningful improvement over the original U-Net. SwinUNet, despite its innovative use of self-attention mechanisms, falls slightly behind in terms of F1 score due to its lower recall, suggesting it might be less effective in capturing all true positives in the dataset.\r\n\r\nThe convolutional network models tend to overfit the data but early-stop effectively prevented it and kept the generalization of the models. The loss score of Swin-Unet shows a larger fluctuation compared to the other two models. Instead of a smooth decrease, it oscillates but converges better than the other two models. A slight over-fitting can still be observed, but the Swin-Unet has shown its advantage in training convergence and stability, which is probably due to the regularization in the structure.\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l c c c c c c c c} \\hline Model & Loss & Accuracy & Precision & Recall & Specificity & ROC AUC & PR AUC & F1 Score \\\\ \\hline U-Net & 0.088542 & 0.968302 & 0.984371 & 0.88302 & 0.995516 & 0.989216 & 0.97749 & 0.93093 \\\\ U-Net+HBN & 0.087765 & 0.968377 & 0.982626 & 0.884932 & 0.995006 & 0.9895 & 0.977889 & 0.931222 \\\\ U-Net 3p & 0.087982 & 0.968429 & 0.984148 & 0.883778 & 0.995442 & 0.98934 & 0.97778 & 0.931242 \\\\ U-Net 3p+HBN & 0.087617 & 0.968456 & 0.982225 & 0.885663 & 0.994876 & 0.989454 & 0.977989 & **0.931434** \\\\ Swin-Unet & 0.095491 & 0.967722 & 0.989644 & 0.875763 & 0.997067 & 0.986288 & 0.973336 & 0.929214 \\\\ Swin-Unet+HBN & 0.09571 & 0.967662 & 0.986882 & 0.878033 & 0.996264 & 0.986269 & 0.973432 & 0.929263 \\\\ \\hline \\end{tabular}\r\n\\end{table}\r\nTable 6.5: Performance Metrics of U-Net/U-Net 3P/Swin-Unet with HBN\r\n\r\nFigure 6.5: 5-fold loss curve of U-Net 3p(L) and Swin-Unet(R)T-tests on the two variant models were conducted, and the result (table 6.6) reflects that the U-Net 3p has a significantly better F1 score when with the HBN structure. However, the HBN only brought a very slight increase in performance to Swin-Unet.\r\n\r\nIn conclusion, while U-Net3+ achieves the highest F1 score, indicating the best balance between precision and recall, SwinUNet's stable convergence and resistance to overfitting make it a strong contender, especially in scenarios where overfitting is a concern.\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l l c c c} \\hline \\hline Model1 & Model2 & T-statistic & P-value & Significance \\\\ \\hline U-Net 3p+HBN & U-Net 3p & 5.6771 & \\(<\\)0.0001 & YES \\\\ Swin-Unet+HBN & Swin-Unet & 1.3956 & 0.1629 & NO \\\\ \\hline \\hline \\end{tabular}\r\n\\end{table}\r\nTable 6.6: T-test on U-Net 3p and Swin-Unet (with/without HBN)\r\n\r\n## Chapter 7 AA-Unet, a New Multi-scale, Convolutional Attention Based Architecture\r\n\r\nIn the realm of medical image segmentation, U-Net has established itself as a highly effective architecture, particularly for tasks requiring precise localization and delineation of structures.", "mimetype": "text/plain", "start_char_idx": 81759, "end_char_idx": 84746, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c6948006-a008-4953-be8c-72810d5a10ae": {"__data__": {"id_": "c6948006-a008-4953-be8c-72810d5a10ae", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f460512b-c36c-490d-946f-ff954d410605", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "2ab250c9c90044f59460119d98667614cbf7af1dc4990c62b655dcb8e2c85772", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c837d2ad-7549-438f-b65a-b85d14d5e56b", "node_type": "1", "metadata": {}, "hash": "a9f30fd76c51870798eeb2a1bd4b6fa01800a705755b3f815ce6d111d206210e", "class_name": "RelatedNodeInfo"}}, "text": "\\begin{table}\r\n\\begin{tabular}{l l c c c} \\hline \\hline Model1 & Model2 & T-statistic & P-value & Significance \\\\ \\hline U-Net 3p+HBN & U-Net 3p & 5.6771 & \\(<\\)0.0001 & YES \\\\ Swin-Unet+HBN & Swin-Unet & 1.3956 & 0.1629 & NO \\\\ \\hline \\hline \\end{tabular}\r\n\\end{table}\r\nTable 6.6: T-test on U-Net 3p and Swin-Unet (with/without HBN)\r\n\r\n## Chapter 7 AA-Unet, a New Multi-scale, Convolutional Attention Based Architecture\r\n\r\nIn the realm of medical image segmentation, U-Net has established itself as a highly effective architecture, particularly for tasks requiring precise localization and delineation of structures. From the last chapter, the U-Net structure and its advanced variants have also performed well in the wildfire growth prediction task.\r\n\r\nFrom U-Net 3+, it was concluded that the aggregation of multi-scale feature maps helps the inference process. Additionally, although Swin-Unet fell behind the convolutional U-shape networks by a small gap, the attention mechanism has revealed its unique strength. I sought to explore the room for improvement based on U-net, particularly in capturing multi-scale context and enhancing feature selection through attention mechanisms. To address these limitations, this chapter proposes AA-Unet.\r\n\r\nThe chapter starts by introducing the structure of AA-Unet, and then explains the novel points in this model in detail. Finally, it supports the idea with the experimental results of comparison to models from the last chapter as well as the ablation study.\r\n\r\nThe AA-Unet architecture is an enhancement of the traditional U-Net, designed to improve segmentation performance by integrating advanced convolutional techniques. The encoder path of the AA-Unet consists of multiple layers of Atrous Spatial Pyramid Convolution (ASPC) Blocks, which replace the standard convolutional layers found in the original U-Net. These ASPC layers employ dilated convolutions with varying dilation rates, capturing multi-scale features and providing a richer representation of the input image. The decoder path mirrors the encoder's structure, utilizing transpose convolutions to upsample the feature maps. A key innovation in the AA-Unet is the replacement of the standard concatenation-based skip connections with convolutional attention mechanisms. These attention mechanisms dynamically weigh the features from the encoder before merging them with the corresponding decoder features, enhancing the model's ability to focus on the most relevant information. AA-Unet is a network that not only preserves the spatial hier\r\n\r\nFigure 7.1: AA-Unet+HBN Structure\r\n\r\n[MISSING_PAGE_EMPTY:70]\r\n\r\nnetwork, residual links are incorporated within the ASPC layers. In figure 7.2, p='same' means that padding is automatically calculated and filled surrounding the image to keep spatial dimension after convolution operations.\r\n\r\n### 7.3 Windowed Convolutional Attention (WCA)\r\n\r\nIn the AA-Unet, the skip connections between the encoder and decoder paths have been significantly enhanced with the introduction of the Windowed Convolutional Attention (WCA) mechanism. This new approach is inspired by the principles of attention [36] but is implemented using convolutional layers.\r\n\r\nFigure 7.3: Windowed Convolutional Attention (WCA)\r\n\r\nThe structure of the Windowed Convolutional Attention mechanism is as follows:\r\n\r\n1. **Replacing the Projection Matrices for QKV:** In traditional attention mechanisms, Q (Query), K (Key), and V (Value) are generated using projection matrices. In the Windowed Convolutional Attention, Q, K, and V are instead derived from three separate 1\\(\\times\\)1 convolutional layers. Q comes from the decoder input, and K, V come from the encoder output at the same level.\r\n2. **Generating the Attention Score:** K and V are stacked together and passed through a convolutional layer with a kernel size equal to the window size. The output of this convolutional layer is then processed through a softmax operation to produce a single-layer attention score.\r\n3.", "mimetype": "text/plain", "start_char_idx": 84129, "end_char_idx": 88137, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c837d2ad-7549-438f-b65a-b85d14d5e56b": {"__data__": {"id_": "c837d2ad-7549-438f-b65a-b85d14d5e56b", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c6948006-a008-4953-be8c-72810d5a10ae", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "7671f96c9424cbb14873d55f87bd40c9684acfec40755d5eceda7a36f2d38005", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "895a9d59-1e28-4753-bc46-84a1be19a090", "node_type": "1", "metadata": {}, "hash": "5b084679ce5367a1e29ceac720120bb37cce961f9e6f7f9a8db658511d7288be", "class_name": "RelatedNodeInfo"}}, "text": "Figure 7.3: Windowed Convolutional Attention (WCA)\r\n\r\nThe structure of the Windowed Convolutional Attention mechanism is as follows:\r\n\r\n1. **Replacing the Projection Matrices for QKV:** In traditional attention mechanisms, Q (Query), K (Key), and V (Value) are generated using projection matrices. In the Windowed Convolutional Attention, Q, K, and V are instead derived from three separate 1\\(\\times\\)1 convolutional layers. Q comes from the decoder input, and K, V come from the encoder output at the same level.\r\n2. **Generating the Attention Score:** K and V are stacked together and passed through a convolutional layer with a kernel size equal to the window size. The output of this convolutional layer is then processed through a softmax operation to produce a single-layer attention score.\r\n3. **Element-wise Product:** An element-wise matrix product (dot product) was used to apply the score weight on V.\r\n\r\nCompared to traditional attention mechanisms that rely on global context and projection matrices for computing Q, K, and V, the Windowed Convolutional Attention in\r\n\r\nFigure 7.4: Data Flow in WCA\r\n\r\nAA-Unet offers some advantages. Benefiting from the computational efficiency and simplicity of convolutions, WCA could project and perform windowed attention with a lighter spatial computation cost.\r\n\r\n### 7.4 Multi-Head WCA\r\n\r\nBuilding upon the original WCA, the multi-head WCA introduces several key modifications to enhance feature representation and model performance. This advanced approach leverages the benefits of multiple attention heads to capture diverse features and improve the model's performance in segmenting complex structures.\r\n\r\nIn the multi-head WCA, Q and K are derived from the decoder and encoder inputs, which is similar to the original WCA from the last section. However, instead of handling these matrices as single entities, the multi-head approach stacks Q and K in an interleaved manner, ensuring that features with the spatial index are adjacent channel-wise (For example, point(C=0, i=1, j=3) and point(C=1, i=1, j=3)). Once stacked, a grouped convolutional layer is applied to the interleaved Q and K. By setting the group parameter to the number of attention heads, the grouped convolution effectively partitions the channels into multiple groups, each corresponding to a different attention head. This operation\r\n\r\nFigure 7.5: Data Flow in Multi-head WCA\r\n\r\nenables the model to compute attention scores that represent various perspectives of the input features. The resulting attention scores, comprising multiple channels corresponding to the different heads, undergo a softmax operation to ensure they sum to one within each head. These multi-head attention scores are then repeated in an interleaved manner to match the dimensionality of V. Specifically, the first (\\(total_{channels}/num_{heads}\\)) features in V correspond to the first head, and so on, ensuring that the attention scores are correctly aligned with their corresponding features in V. As in the original WCA, the adjusted feature maps are then passed through a layer normalization step to stabilize the training process, and a residual link is added to maintain effective gradient flow and enhance model stability. By leveraging multiple attention heads, the multi-head WCA captures a wider range of features and interactions within the input data, allowing the model to attend to different aspects of the features simultaneously.\r\n\r\n### 7.5 Experimental Result\r\n\r\nIn the experiment, I used AA-Unet with head numbers equal to \\(2^{layer-1}\\) (1,2,4,8). The AA-Unet achieved the highest F1 Score of 93.18%, surpassing U-Net (93.12%), U-Net 3+ (93.14%), and Swin-Unet (92.93%). This indicates that AA-U-net provides the best overall performance in terms of accurately and reliably identifying positive cases while minimizing false positives and false negatives.\r\n\r\nIn addition to its superior F1 Score, AA-Unet also demonstrated strong performance in other key metrics. It recorded the lowest Loss value of 0.086323, indicating better model fitting and lower prediction errors. The model achieved a high Accuracy of 96.87%, reflecting its reliability in making correct predictions. For Precision and Recall, AA-Unet scored 98.54% and 88.37%, respectively, showing a good balance in identifying true positives while maintaining high correctness in positive predictions.", "mimetype": "text/plain", "start_char_idx": 87336, "end_char_idx": 91723, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "895a9d59-1e28-4753-bc46-84a1be19a090": {"__data__": {"id_": "895a9d59-1e28-4753-bc46-84a1be19a090", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c837d2ad-7549-438f-b65a-b85d14d5e56b", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "be1f38b4ba7d10e883e7aecc223a9a59edde0f30ba2a48c5272658dee7d936ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7f97de6b-3235-491d-bd7b-91adfde98655", "node_type": "1", "metadata": {}, "hash": "50dde6c3c7fff912478feffb94f4c1d91710eabe8acc575c14e2d1e190e9217c", "class_name": "RelatedNodeInfo"}}, "text": "The AA-Unet achieved the highest F1 Score of 93.18%, surpassing U-Net (93.12%), U-Net 3+ (93.14%), and Swin-Unet (92.93%). This indicates that AA-U-net provides the best overall performance in terms of accurately and reliably identifying positive cases while minimizing false positives and false negatives.\r\n\r\nIn addition to its superior F1 Score, AA-Unet also demonstrated strong performance in other key metrics. It recorded the lowest Loss value of 0.086323, indicating better model fitting and lower prediction errors. The model achieved a high Accuracy of 96.87%, reflecting its reliability in making correct predictions. For Precision and Recall, AA-Unet scored 98.54% and 88.37%, respectively, showing a good balance in identifying true positives while maintaining high correctness in positive predictions. AA-Unet excelled in Specificity with a value of 99.58%, the highest among the compared models, indicating its effectiveness\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l c c c c c c c c} \\hline Model & Loss & Accuracy & Precision & Recall & Specificity & ROC AUC & PR AUC & F1 Score \\\\ \\hline U-Net+HBN & 0.087765 & 0.968377 & 0.982626 & 0.884932 & 0.995006 & 0.9895 & 0.977889 & 0.931222 \\\\ U-Net 3p+HBN & 0.087617 & 0.968456 & 0.982225 & 0.885663 & 0.994876 & 0.989454 & 0.977989 & 0.931434 \\\\ Swin-Unet+HBN & 0.09571 & 0.967662 & 0.986882 & 0.878033 & 0.996264 & 0.986269 & 0.973432 & 0.929263 \\\\ AA-Unet & 0.086757 & 0.968625 & 0.985697 & 0.883129 & 0.995908 & 0.989815 & 0.97843 & 0.931593 \\\\ AA-Unet+HBN & 0.086323 & 0.968692 & 0.985361 & 0.883718 & 0.995808 & 0.989976 & 0.978659 & **0.931772** \\\\ \\hline \\end{tabular}\r\n\\end{table}\r\nTable 7.1: Performance Metrics of AA-Unet, U-Net, U-net 3+ and Swin-Unetin correctly identifying negative instances. The model also performed well in ROC AUC (98.99%) and PR AUC (97.87%), demonstrating its strong capability in distinguishing between positive and negative classes and maintaining a good precision-recall trade-off.\r\n\r\nAdditionally, I have carried out the T-test on the significance of AA-Unet against the baseline model regarding the F1 score. The P-value is close to the threshold of 0.05 but still not enough to prove the statistical significance of the AA-UNet. However, AA-UNet without HBN tends to perform better than AA-Unet with HBN. This relationship was also observed in the ablation study on Swin-Unet.\r\n\r\n### 7.6 Ablation Study\r\n\r\nAn ablation study was conducted to prove the effectiveness of different architectural components on the performance of the AA-Unet model. Specifically, the study compared the performance of the following models: the baseline U-Net, AA-Unet without the Atrous Spatial Pyramid Convolution (ASPC) structure, AA-Unet without the Windowed Convolutional Attention (WCA) structure, and the full AA-Unet.\r\n\r\nThe baseline U-Net achieved an F1 Score of 93.12%, serving as a reference for evaluating the improvements introduced by the AA-Unet components. The AA-Unet without the ASPC structure showed a slight increase in recall (88.57%) compared to the baseline but a minor decrease in precision (98.22%).", "mimetype": "text/plain", "start_char_idx": 90910, "end_char_idx": 94007, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7f97de6b-3235-491d-bd7b-91adfde98655": {"__data__": {"id_": "7f97de6b-3235-491d-bd7b-91adfde98655", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "895a9d59-1e28-4753-bc46-84a1be19a090", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "50c3e97e6d8120c6e0821a4d0db7d111872fe8e1e3f35376ef816cb5b9bc4431", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "417a288e-7421-44bf-998b-29e205d8eb4a", "node_type": "1", "metadata": {}, "hash": "8afbf181352dd2631ef55fe8e22a2f92ff563d6755be4210c7e0d5af9bb81c53", "class_name": "RelatedNodeInfo"}}, "text": "This relationship was also observed in the ablation study on Swin-Unet.\r\n\r\n### 7.6 Ablation Study\r\n\r\nAn ablation study was conducted to prove the effectiveness of different architectural components on the performance of the AA-Unet model. Specifically, the study compared the performance of the following models: the baseline U-Net, AA-Unet without the Atrous Spatial Pyramid Convolution (ASPC) structure, AA-Unet without the Windowed Convolutional Attention (WCA) structure, and the full AA-Unet.\r\n\r\nThe baseline U-Net achieved an F1 Score of 93.12%, serving as a reference for evaluating the improvements introduced by the AA-Unet components. The AA-Unet without the ASPC structure showed a slight increase in recall (88.57%) compared to the baseline but a minor decrease in precision (98.22%). The AA-Unet without the WCA structure showed a similar trend of a slight increase in recall (88.54%) and a small decrease in precision\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l c c c c c c c} \\hline Model & Loss & Accuracy & Precision & Recall & Specificity & ROC AUC & PR AUC & F1 Score \\\\ \\hline U-Net+HBN & 0.087765 & 0.968377 & 0.982626 & 0.884932 & 0.995006 & 0.9895 & 0.977889 & 0.931222 \\\\ AA-Unet+HBN without ASPC 3p & 0.087617 & 0.968456 & 0.982225 & 0.88563 & 0.994876 & 0.989454 & 0.977989 & 0.931434 \\\\ AA-Unet+HBN without WCA & 0.087543 & 0.968453 & 0.982441 & 0.885431 & 0.994946 & 0.989541 & 0.978017 & 0.931411 \\\\ AA-Unet+HBN & 0.086323 & 0.968692 & 0.985361 & 0.883718 & 0.995808 & 0.989976 & 0.978659 & **0.931772** \\\\ \\hline \\end{tabular}\r\n\\end{table}\r\nTable 7.3: Performance Metrics of the Ablation Study on AA-Unet\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l c c c c c} \\hline Model & Model2 & T-statistic & P-value & Significance \\\\ \\hline AA-UNet+HBN & U-Net+HBN & 1.9095 & 0.05621 & NO \\\\ AA-UNet+HBN & AA-UNet & -2.807664319 & 0.0049 & NO \\\\ \\hline \\end{tabular}\r\n\\end{table}\r\nTable 7.2: T-test on AA-Unet/U-Net with HBN(98.24%). However, both models achieved a higher F1 than the baseline model but lower than the complete AA-UNet. This evidence illustrates that both novel components in AA-UNet have brought a performance boost in the prediction task.\r\n\r\nThe ablation study highlights the significant contributions of both the ASPC and WCA structures in enhancing the performance of the AA-Unet. The complete AA-Unet, integrating both enhancements, consistently outperforms the baseline U-Net and its simplified variants across multiple metrics, particularly the F1 Score, underscoring the effectiveness of these architectural innovations in accurately predicting wildfire growth.\r\n\r\n## Chapter 8 Spread Error Attenuation Field (SEAF)\r\n\r\nThis chapter proposes a new idea regarding enhancing specific types of error metrics computation for image segmentation tasks. The effectiveness of this idea has not been fully proven through the experiment, however, I would like to share the concept for its hidden potential.\r\n\r\n### 8.1 Introduction\r\n\r\nThe Spread Error Attenuation Field (SEAF) is introduced as a novel approach to enhance error/loss calculations for 2D segmentation tasks conducted on a 2D grid. The essence of SEAF is to impose an additional penalty on clusters of erroneous predictions that are spatially close to each other, which could be particularly useful in domains such as forest wildfire prediction because the additional punishment will push the model to pay higher attention to the growing fire edges, providing precise burned area shapes.", "mimetype": "text/plain", "start_char_idx": 93211, "end_char_idx": 96679, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "417a288e-7421-44bf-998b-29e205d8eb4a": {"__data__": {"id_": "417a288e-7421-44bf-998b-29e205d8eb4a", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7f97de6b-3235-491d-bd7b-91adfde98655", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "7c3bdb999ab5ff0aba6d71be6aaf6574571f6b459f7e687d9ab1dbadec2ba2e8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f175f641-1143-4c5b-85f2-c922e83c37be", "node_type": "1", "metadata": {}, "hash": "db9c9096b2e101a3657a08e56e8bb4a240cba7d9dec0118fea5914c43b9e063a", "class_name": "RelatedNodeInfo"}}, "text": "## Chapter 8 Spread Error Attenuation Field (SEAF)\r\n\r\nThis chapter proposes a new idea regarding enhancing specific types of error metrics computation for image segmentation tasks. The effectiveness of this idea has not been fully proven through the experiment, however, I would like to share the concept for its hidden potential.\r\n\r\n### 8.1 Introduction\r\n\r\nThe Spread Error Attenuation Field (SEAF) is introduced as a novel approach to enhance error/loss calculations for 2D segmentation tasks conducted on a 2D grid. The essence of SEAF is to impose an additional penalty on clusters of erroneous predictions that are spatially close to each other, which could be particularly useful in domains such as forest wildfire prediction because the additional punishment will push the model to pay higher attention to the growing fire edges, providing precise burned area shapes. This approach aims to incentivize the model to learn and predict patterns with higher resolution rather than making broad area estimations.\r\n\r\nFigure 8.1: A SEAF Example with grouped error\r\n\r\nFigure 8.2: A SEAF Example without grouped error\r\n\r\n### 8.2 Core Idea\r\n\r\nTo encourage the model to learn and predict patterns in high resolution instead of making an area estimation, errors appearing in groups shall get penalized harder. The primary objective of SEAF is to penalize grouped prediction errors more severely to encourage the model to improve its spatial accuracy. The result of SEAF is an enhanced form of the error mask, which could be used for BCELoss in my experiments or any criterion functions relying on it.\r\n\r\n#### SEAF Kernel\r\n\r\nA convolutional kernel is designed with a weighted influence that decreases with distance from the center pixel. Each pixel within the kernel's range contributes to the total penalty based on its distance from the center, thus defining layers of influence.\r\n\r\n#### Layer Definition\r\n\r\nThe layers are defined based on the distance from the central pixel, and this definition is flexible. For instance, instead of assigning a single distance to each layer (e.g., layer one for pixels at distance 1), layers can encompass a range of distances (e.g., layer one for pixels at distances 1-2). Two common methods for defining these layers are:\r\n\r\n1. Geometric Perspective (Grid A): Defines layers clearly based on geometric distances.\r\n\r\nFigure 8.3: SEAF Kernel2. **Manhattan Distance (Grid B):** Utilizes the Manhattan distance to allow flexible weight distribution, which was adopted in my thesis project.\r\n\r\n#### Weight Calculation of Pixels\r\n\r\nTo ensure that the influence of surrounding pixels does not exceed that of the center pixel, the weight summation in any layer \\(n\\) should not be greater than that of the previous layer \\(n-1\\). This attenuation is governed by an attenuation factor \\(\\alpha\\), ideally equal to or greater than 1. The weight function for any pixel \\(p\\) in layer \\(n\\) is defined as follows:\r\n\r\n\\[W_{p}^{n}=\\begin{cases}1&\\text{if }n=0\\\\ \\frac{1}{2\\times\\alpha^{n}\\times\\text{num\\_of\\_P(n)}}&\\text{if }n>0\\end{cases} \\tag{8.1}\\]\r\n\r\nHere, the \\(\\frac{1}{2}\\) term accounts for the double counting of the same error during convolution.\r\n\r\nFigure 8.4: Grid A(Left) & Grid B(Right)\r\n\r\n#### OR Operation After Spread Using Error Mask (optional)\r\n\r\nThe SEAF method involves an optional element-wise product between the diffused error and the original error to capture the spread of cluster errors. Ideally, I expect a binary error mask instead of the original error, but applying a threshold function would make the error not differentiable and hinder the gradient descent. Alternatively, I could apply the original error as a soft version of the error mask. This operation is expected to help in identifying and penalizing clustered errors effectively.\r\n\r\n#### Additional Scaling Factor (optional)\r\n\r\nThe original idea regarding the relationship between outer layers and inner layers was that outer layers should always have smaller total weights, which means that the pixel's distance from the center is expected to be negatively correlated to its influence even under extreme cases when a layer only consists of wrong pixels. However, that case is relatively rare to happen. When trying to reduce the weight of the outer layers, the extra punishment produced by each pixel gets smaller.", "mimetype": "text/plain", "start_char_idx": 95805, "end_char_idx": 100132, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f175f641-1143-4c5b-85f2-c922e83c37be": {"__data__": {"id_": "f175f641-1143-4c5b-85f2-c922e83c37be", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "417a288e-7421-44bf-998b-29e205d8eb4a", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "05e402de624f38869e68240508ee3bd9785a3f44d06566e3ccd251bf0fe6bd9f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b3f636f4-49f2-4783-8aab-d67a8843f0fe", "node_type": "1", "metadata": {}, "hash": "2852ae272f923a41774d1a3f89040ef92e279663f6c5eb71ec328e205bb21878", "class_name": "RelatedNodeInfo"}}, "text": "Ideally, I expect a binary error mask instead of the original error, but applying a threshold function would make the error not differentiable and hinder the gradient descent. Alternatively, I could apply the original error as a soft version of the error mask. This operation is expected to help in identifying and penalizing clustered errors effectively.\r\n\r\n#### Additional Scaling Factor (optional)\r\n\r\nThe original idea regarding the relationship between outer layers and inner layers was that outer layers should always have smaller total weights, which means that the pixel's distance from the center is expected to be negatively correlated to its influence even under extreme cases when a layer only consists of wrong pixels. However, that case is relatively rare to happen. When trying to reduce the weight of the outer layers, the extra punishment produced by each pixel gets smaller. I implemented a constant scaling factor to tune the starting value of layer weights, and the experimental result showed that on some occasions, a scaling factor smaller than 1 (amplifying the sum of weight) helps perform better in prediction.\r\n\r\nWhile the sum of weights for layer \\(x\\) should ideally not exceed that of layer \\(x-1\\), rare cases may arise where most or all surrounding pixels are errors. This becomes less likely as the number of pixels in layers increases, warranting consideration of additional scaling factors if needed.\r\n\r\n#### IoU Scaling Factor (optional)\r\n\r\nTo further enhance the SEAF method, I explored the incorporation of the Intersection over Union (IoU) metric as an additional dynamic scaling factor. This approach adjusts the penalization of prediction errors based on the spatial overlap between predicted and actual burned areas. It could be treated as a superior scaling factor and constant, weighting the error based on the relationship between prediction and ground truth masks.\r\n\r\nBy applying \\(\\frac{1}{\\mathrm{IoU}}\\) as a scaling factor, the model becomes more sensitive to spatial prediction errors. Lower IoU values, indicating poor overlap, result in higher penalization, thus encouraging more accurate spatial predictions. This method provides continuous and contextual feedback, dynamically adjusting the error penalty based on the severity of spatial mismatches, which helps the model consistently improve its prediction accuracy.\r\n\r\n[MISSING_PAGE_EMPTY:82]\r\n\r\nI conducted the experiment on enhanced BCELoss using SEAF. Three groups with different optional procedures and parameters were carried out. From the experimental result 8.1, the base SEAF-BCELoss could optimize the performance with some parameters. Among the base SEAF group, the AA-Unet achieved the highest F1 score in the thesis which is 93.20%(0.931966) when K(Kernel Size)=5, A(Attenuation Rate)=0.5, S(Scaling Factor)=1. The two optional procedures I proposed, the error mask and the IoU scaling, did not achieve higher scores from observation. For example, when applying the optional error mask in SEAF-BCELoss, the F1 score of AA-UNet dropped significantly to 93.03%.\r\n\r\nPicking the best settings (K=5, A=0.5, S=1) in SEAF from the table8.1, I conducted the T-test on AA-Unet trained using SEAF-BCELoss and original BCELoss regarding the F1 score, and the result (table 8.2) shows a clear significance that SEAF-BCELoss helped AA-Unet achieve higher F1 score. The T-test further demonstrates the potential of SEAF.\r\n\r\nFigure 8.5 shows an example of the visual result of how the SEAF changes the model's prediction. The input comes from a fire event that happened in BC, in 2015. The SEAF-BCELoss has reduced the false positive (yellow) and false negative (red) pixels predicted by the AA-Unet compared to just the BCELoss.", "mimetype": "text/plain", "start_char_idx": 99241, "end_char_idx": 102972, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b3f636f4-49f2-4783-8aab-d67a8843f0fe": {"__data__": {"id_": "b3f636f4-49f2-4783-8aab-d67a8843f0fe", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f175f641-1143-4c5b-85f2-c922e83c37be", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "69a8ba821467aced3bd5a88b3b550c157c60feedf0318682fa94599e4d02fdc0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ca0bdf4f-0746-4f00-83ab-683f3fdeab7a", "node_type": "1", "metadata": {}, "hash": "4aade64c2acd71aa52f6d0b9372781bde67f6c1fb30d7ace3e65c98273e6c9a8", "class_name": "RelatedNodeInfo"}}, "text": "Picking the best settings (K=5, A=0.5, S=1) in SEAF from the table8.1, I conducted the T-test on AA-Unet trained using SEAF-BCELoss and original BCELoss regarding the F1 score, and the result (table 8.2) shows a clear significance that SEAF-BCELoss helped AA-Unet achieve higher F1 score. The T-test further demonstrates the potential of SEAF.\r\n\r\nFigure 8.5 shows an example of the visual result of how the SEAF changes the model's prediction. The input comes from a fire event that happened in BC, in 2015. The SEAF-BCELoss has reduced the false positive (yellow) and false negative (red) pixels predicted by the AA-Unet compared to just the BCELoss. This visual result provides a straight illustration of the functio\r\n\r\nFigure 8.5: An example of prediction: Ground Truth(L), AA-Unet trained on BCELoss(C) and trained on SEAF-BCELoss(R)\r\n\r\n\\begin{table}\r\n\\begin{tabular}{l l l l l} \\hline LossFunc1 & LossFunc2 & T-statistic & P-value & Significance \\\\ \\hline SEAF-BCELoss & SEAF & 4.6438 & \\(<\\)0.0001 & YES \\\\ \\hline \\end{tabular}\r\n\\end{table}\r\nTable 8.2: T-test on AA-Unet using SEAF-BCELoss/BCELoss with HBNThe results showed that while some combinations of parameters in the SEAF method resulted in improved performance, most attempts did not yield significant performance gains. Therefore, this idea has not been proven to be widely effective yet. However, the approach still shows potential and value, warranting further exploration and refinement.\r\n\r\n## Chapter 9 Conclusions and Future Works\r\n\r\n### 9.1 Conclusions\r\n\r\nIn this thesis, the implementation of wildfire growth prediction tools using deep learning techniques was discussed. Features from multiple data sources were integrated and used to create a national dataset of wildfires in Canada from 1994 to 2021. To fuse the 2D and 1D features, the Hybrid Bottleneck structure was represented, which shows an advantage against MLP implementation. After that, prediction tools using U-Net and two of its extension variants were successfully built. All three models presented a satisfying performance during the test phase. Based on that, a convolutional neural network model called AA-UNet was offered, which deeply utilizes multi-scale and multi-level features with two enhancement modules. At last, I suggest SEAM, an interesting idea regarding error computation enhancement, which has not been fully validated but has potential for future exploration.\r\n\r\n### 9.2 Future Works\r\n\r\nThe completion of this experiment is attributed to each of the procedures mentioned in the thesis. Reflecting on the experiments, here are some possible future works that could help the perfection of the research:\r\n\r\n#### Dataset Making\r\n\r\nI came across different spatial resolutions during data collecting, and the most simple upsampling method was adopted. The quality of data could be limited by the super-resolution challenge during the data processing, and there is room for improvement on this topic.\r\n\r\nRegarding the FWI features, the nearest neighbours algorithm was used to calculate approximation. The interpolation algorithm is a good direction for refining the extraction of the FWI layer. Extra features could also contribute to the model training.\r\n\r\n#### Data Augmentation\r\n\r\nThe wildfire dataset obtained in this thesis has finite samples. Data augmentation is a good method to provide a variety of samples. For example, randomly switching some pixels of the image as a form of noise could be adopted.\r\n\r\n#### Multi-Class Prediction\r\n\r\nIn the thesis, the prediction of binary burned areas has been investigated. If splitting the next-day cumulative burned area into two further sub-parts: the next-day burning area, and the rest cumulative burned area, the prediction models would face bigger challenges but also present more practical value to the field.\r\n\r\n#### Comparison to traditional models\r\n\r\nUnfortunately, I was unable to conduct a comparative experiment between my deep learning implementation and traditional simulation models like Prometheus or FARSITE. Demonstrating a significant advantage of the deep learning model over these traditional models would provide compelling evidence of the potential benefits of deep learning in addressing Canadian wildfire issues. Hard access to certain datasets and specialized expertise requirements of some tools increase the difficulty of conducting this experiment. Ongoing research by our lab will be working with modelling experts in wildfire planning in the government to carry out these simulations in the future.", "mimetype": "text/plain", "start_char_idx": 102321, "end_char_idx": 106851, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ca0bdf4f-0746-4f00-83ab-683f3fdeab7a": {"__data__": {"id_": "ca0bdf4f-0746-4f00-83ab-683f3fdeab7a", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b3f636f4-49f2-4783-8aab-d67a8843f0fe", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "2cb03f98787b23bd4f39d4722e286da0bcc0ced6e128849989c179e40ccb9375", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8e9a0cfa-6cde-4e0d-8e4e-a1bd33ab8660", "node_type": "1", "metadata": {}, "hash": "7a146fbeb351592a0bbf1cd814520d49f6cb93932fba975013ee0ffe80658483", "class_name": "RelatedNodeInfo"}}, "text": "For example, randomly switching some pixels of the image as a form of noise could be adopted.\r\n\r\n#### Multi-Class Prediction\r\n\r\nIn the thesis, the prediction of binary burned areas has been investigated. If splitting the next-day cumulative burned area into two further sub-parts: the next-day burning area, and the rest cumulative burned area, the prediction models would face bigger challenges but also present more practical value to the field.\r\n\r\n#### Comparison to traditional models\r\n\r\nUnfortunately, I was unable to conduct a comparative experiment between my deep learning implementation and traditional simulation models like Prometheus or FARSITE. Demonstrating a significant advantage of the deep learning model over these traditional models would provide compelling evidence of the potential benefits of deep learning in addressing Canadian wildfire issues. Hard access to certain datasets and specialized expertise requirements of some tools increase the difficulty of conducting this experiment. Ongoing research by our lab will be working with modelling experts in wildfire planning in the government to carry out these simulations in the future.\r\n\r\n## References\r\n\r\n* [1] Agriculture and Agri-Food Canada. Semi-decadal land use. [http://www.agr.gc.ca/atlas/landu](http://www.agr.gc.ca/atlas/landu), 2021. Goverment of Canada.\r\n* [2] Frank A Albini. _Estimating wildfire behavior and effects_, volume 30. Department of Agriculture, Forest Service, Intermountain Forest and Range..., 1976.\r\n* [3] Patricia L Andrews et al. The rothermel surface fire spread model and associated developments: A comprehensive explanation. 2018.\r\n* [4] Andre Beaudoin, Pierre Bernier, Luc Guindon, Philippe Villemaire, Xiaojing Guo, Graham Stinson, Thomas Bergeron, Steen Magnussen, and R.J. Hall. Mapping attributes of canada's forests at moderate resolution through k nn and modis imagery. _Canadian Journal of Forest Research_, 44:521-532, 05 2014.\r\n* [5] Esri Canada. Provinces and territories of Canada. [https://hub.arcgis.com/datasets/d3fef65386df4e63b02d6e23bb98a1ee_0/about](https://hub.arcgis.com/datasets/d3fef65386df4e63b02d6e23bb98a1ee_0/about), 2024. ArcGIS Hub.\r\n* [6] Health Canada. Wildfire smoke and your health. [https://www.canada.ca/en/health-canada/services/publications/healthy-living/wildfire-smoke-health.html](https://www.canada.ca/en/health-canada/services/publications/healthy-living/wildfire-smoke-health.html), 2024. Accessed: 2024-07-12.\r\n* [7] Hu Cao, Yueyue Wang, Joy Chen, Dongsheng Jiang, Xiaopeng Zhang, Qi Tian, and Manning Wang. Swin-unet: Unet-like pure transformer for medical image segmentation. In _European conference on computer vision_, pages 205-218. Springer, 2022.\r\n* [8] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. _IEEE transactions on pattern analysis and machine intelligence_, 40(4):834-848, 2017.\r\n\r\n* [9] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. _CoRR_, abs/1706.05587, 2017.\r\n* [10] Leckie D.G. Tinis S. Dyk, A. and S. Ortlepp. Canada's national deforestation monitoring system: System description. url[https://ostrnrcandostrncan.canada.ca/handle/1845/244040](https://ostrnrcandostrncan.canada.ca/handle/1845/244040), 2015. Natural Resources Canada, Canadian Forest Service, Pacific Forestry Centre.\r\n* [11] Mark A Finney. _FARSITE, Fire Area Simulator-model development and evaluation_. Number 4.", "mimetype": "text/plain", "start_char_idx": 105690, "end_char_idx": 109289, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8e9a0cfa-6cde-4e0d-8e4e-a1bd33ab8660": {"__data__": {"id_": "8e9a0cfa-6cde-4e0d-8e4e-a1bd33ab8660", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ca0bdf4f-0746-4f00-83ab-683f3fdeab7a", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "3dee601b71db0bc53c492f5b26aa9e1196f90fdfec246c6f09607b21db1c8d9c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e749f28e-983e-40a3-a8a5-fc8cff84dcb9", "node_type": "1", "metadata": {}, "hash": "48d50fd0df16f721abc17872b063ca4d60e897103a4d0f14a4ef1a12f269bdee", "class_name": "RelatedNodeInfo"}}, "text": "* [9] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. _CoRR_, abs/1706.05587, 2017.\r\n* [10] Leckie D.G. Tinis S. Dyk, A. and S. Ortlepp. Canada's national deforestation monitoring system: System description. url[https://ostrnrcandostrncan.canada.ca/handle/1845/244040](https://ostrnrcandostrncan.canada.ca/handle/1845/244040), 2015. Natural Resources Canada, Canadian Forest Service, Pacific Forestry Centre.\r\n* [11] Mark A Finney. _FARSITE, Fire Area Simulator-model development and evaluation_. Number 4. US Department of Agriculture, Forest Service, Rocky Mountain Research Station, 1998.\r\n* Agency FireData. Canadian Forest Service. [http://cwfis.cfs.nrcan.gc.ca/ha/nfdb](http://cwfis.cfs.nrcan.gc.ca/ha/nfdb), 2016. Natural Resources Canada, Canadian Forest Service, Northern Forestry Centre, Edmonton, Alberta.\r\n* [13] Canadian Forest Service. National burned area composite. [https://cwfis.cfs.nrcan.gc.ca](https://cwfis.cfs.nrcan.gc.ca), 2023. Natural Resources Canada, Canadian Forest Service, Northern Forestry Centre, Edmonton, Alberta.\r\n* [14] Sriram Ganapathi Subramanian and Mark Crowley. Using spatial reinforcement learning to build forest wildfire dynamics models from satellite images. _Frontiers in ICT_, 5:6, 2018.\r\n* [15] Rafik Ghali and Moulay A. Akhloufi. Deep learning approaches for wildland fires using satellite remote sensing data: Detection, mapping, and prediction. _Fire_, 6(5), 2023.\r\n* [16] Laurence Hawker, Peter Uhe, Luntadila Paulo, Jeison Sosa, James Savage, Christopher Sampson, and Jeffrey Neal. A 30 m global map of elevation with forests and buildings removed. _Environmental Research Letters_, 17(2):024016, 2022.\r\n* [17] Kelvin G Hirsch. _Canadian forest fire behavior prediction (FBP) system: user's guide_. Number 7. 1996.\r\n* [18] J. Hodges and B. Lattimer. Wildland fire spread modeling using convolutional neural networks. _Fire Technology_, pages 1-28, 2019.\r\n* [19] Huimin Huang, Lanfen Lin, Ruofeng Tong, Hongjie Hu, Qiaowei Zhang, Yutaro Iwamoto, Xianhua Han, Yen-Wei Chen, and Jian Wu. Unet 3+: A full-scale connected unet for medical image segmentation. In _ICASSP 2020-2020 IEEE international conference on acoustics, speech and signal processing (ICASSP)_, pages 1055-1059. IEEE, 2020.\r\n* Huot et al. [2020] F. Huot, R. Hu, M. Ihme, Qing Wang, J. Burge, Tianjian Lu, Jason Hickey, Yi-Fan Chen, and John R. Anderson. Deep learning models for predicting wildfires from historical remote-sensing data. _ArXiv_, abs/2010.07445, 2020.\r\n* Jain et al. [2022] Piyush Jain, Dante Castellanos-Acuna, Sean CP Coogan, John T Abatzoglou, and Mike D Flannigan. Observed increases in extreme fire weather driven by atmospheric humidity and temperature. _Nature Climate Change_, 12(1):63-70, 2022.\r\n* Jain et al. [2020] Piyush Jain, Sean CP Coogan, Sriram Ganapathi Subramanian, Mark Crowley, Steve Taylor, and Mike D Flannigan. A review of machine learning applications in wildfire science and management. _Environmental Reviews_, 28(4):478-505, 2020.\r\n* Neal [2023] Laurence Hawker Jeffrey Neal. FABDEM v1-2.", "mimetype": "text/plain", "start_char_idx": 108696, "end_char_idx": 111832, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e749f28e-983e-40a3-a8a5-fc8cff84dcb9": {"__data__": {"id_": "e749f28e-983e-40a3-a8a5-fc8cff84dcb9", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8e9a0cfa-6cde-4e0d-8e4e-a1bd33ab8660", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "b78404958c02ffc0d3bf4a36618c87635eae66046670aa68bcaa0ad498a1b682", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b1f6fac4-e7cb-4d59-b33a-ad7e50e30562", "node_type": "1", "metadata": {}, "hash": "09d7371593fb984f6e695c1ff4e543c5094fb8902fb655b6635c4269645c8a1b", "class_name": "RelatedNodeInfo"}}, "text": "_ArXiv_, abs/2010.07445, 2020.\r\n* Jain et al. [2022] Piyush Jain, Dante Castellanos-Acuna, Sean CP Coogan, John T Abatzoglou, and Mike D Flannigan. Observed increases in extreme fire weather driven by atmospheric humidity and temperature. _Nature Climate Change_, 12(1):63-70, 2022.\r\n* Jain et al. [2020] Piyush Jain, Sean CP Coogan, Sriram Ganapathi Subramanian, Mark Crowley, Steve Taylor, and Mike D Flannigan. A review of machine learning applications in wildfire science and management. _Environmental Reviews_, 28(4):478-505, 2020.\r\n* Neal [2023] Laurence Hawker Jeffrey Neal. FABDEM v1-2. [https://doi.org/10.5523/bris.s5hqmjcdj8yo2ibzi9b4ew3sn](https://doi.org/10.5523/bris.s5hqmjcdj8yo2ibzi9b4ew3sn), 2023. University of Bristol.\r\n* Kondylatos et al. [2022] Spyros Kondylatos, Ioannis Prapas, Michele Ronco, I. Papoutsis, Gustau Camps-Valls, M. Piles, M. Fernandez-Torres, and N. Carvalhoais. Wildfire danger prediction and understanding with deep learning. _Geophysical Research Letters_, 49, 2022.\r\n* Markuzon and Kolitz [2009] Natasha Markuzon and Stephan Kolitz. Data driven approach to estimating fire danger from satellite images and weather information. In _2009 IEEE Applied Imagery Pattern Recognition Workshop (AIPR 2009)_, pages 1-7, 2009.\r\n* McElhinny et al. [2020] Megan McElhinny, Justin F Beckers, Chelene Hanes, Mike Flannigan, and Piyush Jain. A high-resolution reanalysis of global fire weather from 1979 to 2018-overwintering the drought code. _Earth System Science Data_, 12(3):1823-1833, 2020.\r\n* Canada [2024] Natural Resources Canada. Canadian forest fire danger rating system (cffdrs). [https://cwfis.cfs.nrcan.gc.ca/background/summary/fdr](https://cwfis.cfs.nrcan.gc.ca/background/summary/fdr), 2024. Accessed: 2024-05-21.\r\n* Canada [2024] Natural Resources Canada. Canadian forest fire weather index (fwi) system. [https://cwfis.cfs.nrcan.gc.ca/background/summary/fwi](https://cwfis.cfs.nrcan.gc.ca/background/summary/fwi), 2024. Accessed: 2024-05-21.\r\n* Parisien et al. [2005] Marc-Andre Parisien, VG Kafka, KG Hirsch, JB Todd, SG Lavoie, PD Maczek, et al. Mapping wildfire susceptibility with the burn-p3 simulation model. 2005.\r\n* Radke et al. [2019] David Radke, Anna Hessler, and Daniel Ellsworth. Firecast: Leveraging deep learning to predict wildfire spread. pages 4575-4581, 2019.\r\n\r\n* [31] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In _Medical image computing and computer-assisted intervention-MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18_, pages 234-241. Springer, 2015.\r\n* [32] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In _Medical image computing and computer-assisted intervention-MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18_, pages 234-241. Springer, 2015.\r\n* [33] Richard C Rothermel.", "mimetype": "text/plain", "start_char_idx": 111237, "end_char_idx": 114243, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b1f6fac4-e7cb-4d59-b33a-ad7e50e30562": {"__data__": {"id_": "b1f6fac4-e7cb-4d59-b33a-ad7e50e30562", "embedding": null, "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2db788cc-fdb2-435a-85c5-d5f9272e1afd", "node_type": "4", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "1ad9b61ea97d47d5c2fd8a1f7b57d39d3142b5677c47251c741925bdc781914b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e749f28e-983e-40a3-a8a5-fc8cff84dcb9", "node_type": "1", "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}, "hash": "b3fa0e265cb868dec30cd2af9ff1386e77325d9af04ab4fbcd491f8f579216ba", "class_name": "RelatedNodeInfo"}}, "text": "* [31] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In _Medical image computing and computer-assisted intervention-MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18_, pages 234-241. Springer, 2015.\r\n* [32] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In _Medical image computing and computer-assisted intervention-MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18_, pages 234-241. Springer, 2015.\r\n* [33] Richard C Rothermel. _A mathematical model for predicting fire spread in wildland fuels_, volume 115. Intermountain Forest & Range Experiment Station, Forest Service, US..., 1972.\r\n* [34] Aman Singh, Rakesh Yadav, Gadug Sudhamshu, Aryan Basnet, and Rahmat Ali. Wildfire spread prediction using machine learning algorithms. _2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)_, pages 1-5, 2023.\r\n* [35] Cordy Tymstra, RW Bryce, BM Wotton, SW Taylor, OB Armitage, et al. Development and structure of prometheus: the canadian wildland fire growth simulation model. _Natural Resources Canada, Canadian Forest Service, Northern Forestry Centre, Information Report NOR-X-417.(Edmonton, AB)_, 2010.\r\n* [36] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. _Advances in neural information processing systems_, 30, 2017.\r\n* [37] Zhong Zheng, Wei Huang, Songnian Li, and Yongnian Zeng. Forest fire spread simulating model using cellular automaton with extreme learning machine. _Ecological Modelling_, 348:33-43, 2017.", "mimetype": "text/plain", "start_char_idx": 113564, "end_char_idx": 115382, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"2db788cc-fdb2-435a-85c5-d5f9272e1afd": {"node_ids": ["eeff5633-dd9e-495c-b291-6cdd7f688259", "f39d083a-2e3e-405d-a1d3-de008decf882", "792fb115-c6ad-49a5-a428-37ddcae0eae8", "2146e9e2-2fb1-4f36-93d2-fbd5cef27c91", "52596574-043d-42af-9aa6-2ac5aa858a10", "b51cdd8f-39ab-4408-bdde-403d4329d8c2", "16366616-e73d-4b7d-a05d-2f8eb6481a8e", "6b683f45-68bd-4ddb-8833-0dc97c41251e", "c41c2d5e-e431-4b0c-8cc4-064a6f9077cb", "d747e369-890d-493a-a830-49d6a831506d", "7897a05f-6f87-43bb-bedd-657dbc79d48a", "db1619be-4e37-4efc-8e84-5ef34eb3153f", "bb70fc6b-1993-4076-ad91-bb1427ee9d27", "9cfbb92d-3dd9-48c1-95a1-01a3f333969b", "d8e46bbd-080a-4519-96fd-6d28df1dca74", "0f2086dc-86f2-46ee-9fc4-3d7ec65e782c", "c739dc1b-64af-4475-9379-553f5f429a74", "fc4fc73a-f083-4bf3-8cb6-ff3f1606b3f9", "3aded430-9d46-4b93-801b-21fcab6a02f1", "fbe9d181-82dc-4f7b-afc0-ab6992f62233", "20ad84dd-9d5f-48ba-95ee-b537b6201223", "7a3971e3-1676-4996-8aec-f0b2bee55abc", "004921a2-cad6-416c-9b4d-580d8208d508", "db000a10-c025-473f-bc19-bf9d0fbee47c", "3e14b145-f2ed-4771-990d-ed6d8b43463d", "9e2e718d-668d-4466-b854-8ac72f90b1d5", "f460512b-c36c-490d-946f-ff954d410605", "c6948006-a008-4953-be8c-72810d5a10ae", "c837d2ad-7549-438f-b65a-b85d14d5e56b", "895a9d59-1e28-4753-bc46-84a1be19a090", "7f97de6b-3235-491d-bd7b-91adfde98655", "417a288e-7421-44bf-998b-29e205d8eb4a", "f175f641-1143-4c5b-85f2-c922e83c37be", "b3f636f4-49f2-4783-8aab-d67a8843f0fe", "ca0bdf4f-0746-4f00-83ab-683f3fdeab7a", "8e9a0cfa-6cde-4e0d-8e4e-a1bd33ab8660", "e749f28e-983e-40a3-a8a5-fc8cff84dcb9", "b1f6fac4-e7cb-4d59-b33a-ad7e50e30562"], "metadata": {"file_path": "C:\\Users\\Alexl\\FYDP---Intelligent-Camera\\data\\5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_name": "5a588bd4-43dc-4d8f-9981-f53f3c050e18_Canada_Wildfire_Next-Day_Spread_Prediction_Tools_Using_Deep_Learning_-_Xiang_Fang.mmd", "file_size": 115390, "creation_date": "2024-07-25", "last_modified_date": "2024-07-25"}}}}